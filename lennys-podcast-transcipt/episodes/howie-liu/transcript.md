---
guest: Howie Liu
title: How we restructured Airtable's entire org for AI | Howie Liu (co-founder and
  CEO)
youtube_url: https://www.youtube.com/watch?v=GT0jtVjRy2E
video_id: GT0jtVjRy2E
publish_date: 2025-08-31
description: 'Howie Liu is the co-founder and CEO of Airtable, the no-code platform
  valued at around $12 billion. After a viral tweet declared “Airtable is dead” based
  on incorrect data, Howie led a...

  '
duration_seconds: 6042.0
duration: '1:40:42'
view_count: 28715
channel: Lenny's Podcast
keywords:
- growth
- acquisition
- onboarding
- roadmap
- user research
- iteration
- experimentation
- analytics
- funnel
- conversion
- freemium
- revenue
- hiring
- culture
- leadership
---

# How we restructured Airtable's entire org for AI | Howie Liu (co-founder and CEO)

## Transcript

Howie Liu (00:00:00):
If you were literally founding a new company from scratch with the same mission, how would you execute on that mission using a fully AI native approach? If you can't, then you should find a buyer and then if you really care about this mission, go and start the next carnation of it.

Lenny Rachitsky (00:00:12):
Or people that work for you, how have you adjusted what you expect of them to help them be successful?

Howie Liu (00:00:18):
If you want to cancel all your meetings for like a day or for an entire week and just go play around with every AI product you think could be relevant to Airtable, go do it.

Lenny Rachitsky (00:00:27):
Of the different functions on our product team PM, engineering design, who has had the most success being more productive with these tools?

Howie Liu (00:00:33):
It really does become more about individual attitude. There's a strong advantage to any of those three roles who can kind of cross over into the other two. As a PM, you need to start looking more like a hybrid PM prototyper, who has some good design sensibilities?

Lenny Rachitsky (00:00:49):
Do you see one of these roles being more in trouble than others? Today, my guest is Howie Liu. Howie is the co-founder and CEO of Airtable. I'm having a bunch of conversations on this podcast with founders who are reinventing their decade plus old business in this AI era, to help you navigate this existential transition that every company and product is going through right now. Howie and Airtable's journey is an incredible example of this, and there's so much to learn from what Howie shares in this conversation.

(00:01:20):
We talk about a very interesting trend that I've noticed that Howie is very much an example of, of CEOs almost becoming individual contributors again, getting into the code, building things, leading initiatives themselves. That's something that we call the IC CEO. We also talk about the very specific skills that he believes product managers and product leaders, also engineers and designers need to build to do well in this new world that we're in. Also, how he restructured his company into two groups, a fast thinking group, and a slow thinking group, which allowed their AI investments to significantly accelerate.

(00:01:52):
If you're struggling to figure out how to be successful in this new AI era, this episode is for you. If you enjoy this podcast, don't forget to subscribe and follow it in your favorite podcasting app or YouTube. Also, if you become an annual subscriber of my newsletter, you get a year free of 15 incredible products, including Lovable, Replit, Bolt and Adyen, Linear, Superhuman, Descript, Wispr Flow, Gamma, Perplexity, Warp, Granola, Magic Patterns, Raycast, ChatPRD and Mobit. Check it out at lennysnewsletter.com and click product pass. With that, I bring you Howie Liu.

(00:02:23):
This episode is brought to you by Lucidlink, the storage collaboration platform. You've built a great product, but how you show it through video design and storytelling is what brings it to life. If your team works with large media files, videos, design assets, layered project files, you know how painful it can be to stay organized across locations. Files live in different places. You're constantly asking, is this the latest version? Creative work slows down while people wait for files to transfer.

(00:02:49):
Lucidlink fixes this. It gives your team a shared space in the cloud that works like a local drive. Files are instantly accessible from anywhere. No downloading, no syncing, and always up to date. That means producers, editors, designers, and marketers can open massive files in their native apps, work directly from the cloud, and stay aligned wherever they are. Teams at Adobe, Shopify and top creative agencies use LucidLink to keep their content engine running fast and smooth. Try it for free at lucidlink.com/lenny. That's L-U-C-I-D-L-I-N-K dot com slash Lenny.

(00:03:24):
Today's episode is brought to you by DX, the developer intelligence platform designed by leading researchers. To thrive in the AI era. Organizations need to adapt quickly, but many organization leaders struggle to answer pressing questions like, which tools are working, how are they being used, what's actually driving value? DX provides the data and insights that leaders need to navigate this shift. With DX, companies like Dropbox, Booking.com, Adyen, and Intercom. Get a deep understanding of how AI is providing value to their developers and what impact AI is having on engineering productivity.

(00:03:58):
To learn more, visit DX's website at getdx.com/lenny. That's getdx.com/lenny. Howie, thank you so much for being here and welcome to the podcast.

Howie Liu (00:04:14):
I'm so excited. Thank you, Lenny. I've been a listener from afar for a while now.

Lenny Rachitsky (00:04:19):
I'm really flattered to hear that. I'm also very excited. You've been on quite a journey over the last, is it 13 years, is it longer?

Howie Liu (00:04:27):
Yeah, right about 13.

Lenny Rachitsky (00:04:28):
13 years. I imagine there've been a lot of ups and a lot of downs. I want to talk about all those things. I want to talk about a lot of the lessons that you've learned along the way. I want to start with what I imagine was a very surprising down moment in the history of Airtable. This is something that, unfortunately, something I think about when I think of Airtable. I feel other people may feel this way, is there's this tweet that went super viral, maybe a couple of years ago at this point where someone just shared all this data and they're like, Airtable is dead.

(00:04:57):
They've raised way more money than they're worth. They're not making enough to get from underwater. Yeah, Airtable RIP. What happened there? How much of that was true? How did that go?

Howie Liu (00:05:06):
Yeah, so basically none of it was true. I mean, the surprising thing to me was how viral this tweet went when ... Frankly, I actually look back at this person's other tweets. I think they worked at CB Insights, and the irony is the whole point of that business is to have good data, good data quality around private company data. And they just literally had incorrect numbers by a strong multiple on what our revenue scale was, what our growth rate was. And if it gave me some consolation, I look back and this person had also tweeted about other companies, like Flexport was the last take-down tweet.

(00:05:45):
They have like, "Oh, Flexport's dead" and their evaluation is too high, and blah, blah, blah. And so, I think that the more surprising thing was just like this person has been tweeting a bunch of spicy takes that are not substantiated by real data or correct data, and yet this particular tweet went super viral and that was the perplexing part to me. And then, actually, I think what really gave it legs was on the All In podcast, which is obviously super popular. And I listened to it. They covered it. They were like, "Oh, latest on this week's news, this tweet about Airtable. What do we think about this?"

(00:06:22):
And it almost, I think became a way to talk about a broader theme of what happens to this last generation of highly valued companies, maybe decacorn companies in this new ... And at that point, it was the recent moment for both public and private markets. They did also issue a correction though. All In, did a follow-up episode, a few, I think weeks later saying, "Hey, we got the numbers wrong. We are revising our case and a view on Airtable."

Lenny Rachitsky (00:06:53):
What's that line about how a lie gets around the world some number of times before truth has even this time to get out of bed?

Howie Liu (00:07:02):
Yeah. Well, I think I learned about memes and morality very quickly in that experience. Not a very good social media person, but I think I learned a little more.

Lenny Rachitsky (00:07:10):
Yeah, it's tough. Twitter is such ... The incentives are so misaligned. It's just I tweet something people want to share, not truth.

Howie Liu (00:07:17):
Well, especially ... I mean, there's a lot to like ... I would say, I like the post Elon Twitter more than the pre Elon Twitter because it is just bolder, and I guess I really admire bold product execution where you're not just stuck to the current laurels and they've made so many changes, but I do feel like I get injected into my feed very sensational content all the time, and I mean, it works on me. I can't help but to click on it and engage with it, but it does ... I think it does result in this kind of content, really spreading.

Lenny Rachitsky (00:07:52):
Yeah. Now, Nikita running the show, I don't know if you saw this, there's a new ... We don't need to keep talking about Twitter, but there's a new feature where you take a screenshot of a tweet and it has a huge X.com logo watermark on the top, right? Yeah, just to ... People are sharing these tweets all the time. Yeah.

Howie Liu (00:08:06):
Yeah.

Lenny Rachitsky (00:08:06):
Man. Never a dull moment over there.

Howie Liu (00:08:07):
For sure.

Lenny Rachitsky (00:08:08):
Okay. I want to go in a completely different direction, something that I'm really excited to talk to you about, which is this very emerging trend that I've noticed that I feel like you're at the forefront of CEOs becoming ICs again. It's kind of this move of, IC CEOs. CEOs getting their hands dirty again, building again, getting in the weeds, coating again. I feel like you're again at the forefront of this. Talk about just why you've done this, why you think this is important, and just what that looks like day to day to you versus what your life was like a few years ago.

Howie Liu (00:08:39):
The underlying reason for this shift, at least for me, is that, as we started the company, I was very much in this mode. I was literally writing code both on the backend, thinking about the real time data architecture of our platform, also the front end, the UX. And I would argue that in that founding moment, the initial product market fit finding, and especially for a product that is pure software, we weren't building an operationally heavy business like a dog walking marketplace where the tech is only an afterthought.

(00:09:11):
The tech was the product, right? And in a very Meta sense, Airtable is the platform for other people to build their own apps. So it's all about the attack, like the very intimate design decisions, again, both architecturally and on the front end and the product UX choices. That is the product's value prop. You can't separate those two. You can't say, "Okay, I researched the jobs to be done. Here's the workflow, here's the process, and then, okay, some engineer can just build it as an afterthought."

(00:09:40):
It's those little decisions and really be able to be at the bleeding edge of what's possible both in the browser and with the real-time data architecture. That made the product what it was. I think the same is true for Figma, which actually had a very parallel timeline to us. We both were founded around the same time, both spent two and a half years building the product, hands-on that early team before launching. And when I think now to both the era in between that founding moment and then now as well as now the new gen AI moment, I think there was a maturing era of both SaaS overall and Airtable specifically.

(00:10:19):
Where, as you scale up and you learn how to build teams and organizations and you have to scale up stuff that's not actually those intimate details, but process and people and so on, you kind of get by default further and further away from those details, right? And maybe for some businesses that's fine because no longer is it about finding the details that make for a magical new product market fit. And it is really just about scaling up an existing thing that works and using what I would call more blunt instruments to scale it up, like a more blunt roadmap, a more blunt go-to market execution strategy.

(00:10:56):
Regardless, I think that now, we're entering this moment where ... Certainly every software product in my opinion, has to be refounded because AI is such a paradigm shift, it's not even just like the shift from desktop to mobile or on-prem to cloud where that was more like a very one time and somewhat predictable change in form factor. I think AI is so rapidly evolving that with every evolution, every new model release and every new type of capability that's released, it actually implies novel form factors and novel UX patterns to be invented to fully capitalize on those capabilities.

(00:11:36):
And so to be continuously relevant and to refine product market fit in this era, I think you have to be of the details. There is no looking at it from 10,000 foot view and saying, "Oh, we're just going to throw a bunch of people at this problem." It's actually understanding what is the right product experience and the right business model that backs it up and the right ... everything else to support that engine to take advantage of the capabilities in our product domain.

Lenny Rachitsky (00:12:07):
You have this phrase somewhere where you talk about being the chief taste maker.

Howie Liu (00:12:11):
Yeah.

Lenny Rachitsky (00:12:11):
And to do that, you have to do exactly what you're describing.

Howie Liu (00:12:14):
That's right. I mean, I think that, and I would also say it's actually now also hard to taste the soup without participating in at least some part of creating the soup. Meaning With AI, you can kind of look at the final product and say, "Okay, this feels right or not, or it feels like we're being bold enough and we're properly productizing these new capabilities." But I think to really understand the solution space of what's possible, you have to be in the details.

(00:12:46):
I mean, literally, you can't just look at screenshots or a pre-recorded video of a new product feature. AI is something you have to play with, and ideally you're playing with both the packaged up app or solution that you've built with it, but you're also playing around directly with the underlying primitives who are using the models either via API or via a chat interface. You're really pushing them to the boundaries. Because that's the only way that you really understand what these new ingredients. It's like as a chef, you just gained access to amazing new ingredients, but you have to actually get comfortable with them to put them into a new dish.

Lenny Rachitsky (00:13:23):
And we had Dan Shipper on the podcast, he runs this newsletter and podcast to product a company called Every. And they work with companies to help them become more AI successful and adopt AI and all that stuff. And I asked him, what's the signal that a company will have success adopting AI and seeing huge productivity gains? And he said, does the CEO use ChatGPT or Claude daily?

Howie Liu (00:13:48):
Yeah.

Lenny Rachitsky (00:13:49):
And I feel like you're describing exactly, hourly,

Howie Liu (00:13:51):
Literally hourly, or you could even have a measure of inference costs, right? Like the equivalent underlying inference compute cycles, right?

Lenny Rachitsky (00:14:02):
How many tokens you use?

Howie Liu (00:14:03):
Yeah, I mean, I'm proud to say I am pretty sure I'm still the ... I just checked this recently, but I take pride in being the number one most expensive in inference cost user of Airtable AI, not just within our own company, but I think for a long time I was globally across all our customers vault. I mean, I'm extremely intentionally wasteful. Wasteful in the sense of I'll do something that costs maybe hundreds of dollars of actual inference costs. For instance, doing a lot of LLM calls against long transcripts of let's say, sales calls to extract different types of insights like here's the product apps, identify or here's summaries, et cetera.

(00:14:49):
And we also have now a capability that's basically like an LLM map reduce. So effectively, even if you can't fit the entire corpus of content into one LLM call, because the context window limitations, we'll map through all of this content and break it up into chunks and then perform an LLM call on each one and then perform an aggregation LLM call on those chunks. Very expensive, because you're basically running a highly expensive model against a lot of data and then running it again on the aggregates of that. But for me, hundreds of dollars spent on this exercise is trivial compared to the potential strategic value of having better insights.

(00:15:29):
It's as if a really, really smart chief of staff has gone through and read every single sales call transcript that we've had in the past year and giving me very astute product insights, marketing insights, kind of positioning insights and segmentation insights. That's invaluable. You could pay a consulting firm literally millions of dollars to get that quality of work. So to me, I still think the value versus the actual cost of AI when applied greedily but smartly, it's a crazy ratio. And more people should be aggressively throwing compute cycles at these very high value problems.

Lenny Rachitsky (00:16:11):
Until somebody tweets how you're costing the company so much on AI compute and you guys are going to be underwater.

Howie Liu (00:16:19):
I'm just kidding. It's like how we have personally taken down the cashflow profile of the business.

Lenny Rachitsky (00:16:27):
So CEO's, founders hearing this, they're probably like, okay, I should probably start doing this. What does this actually look like? I imagine you still have a lot of other stuff you got going on once, you got all these ... How do you change your day to day to do this?

Howie Liu (00:16:41):
Yeah, so I actually cut my one-on-one roster by default, and the idea is not that I don't want to spend time one-on-one with people, but rather that I found that the ... Just having more standing one-on-ones actually precludes me from engaging in more timely topics. I like to think of the best types of meetings as very urgency driven. And there's some timely topic, you've discovered some insight. Maybe I talked to some new startup and I learned something from their product or their approach.

(00:17:20):
And I want to bring that into how we're thinking about a new feature at Airtable or even just plant the seed with some different EPD people within Airtable, I want to make most meetings very timely and very informed by real alpha. There's got to be some kind of value and insight to seed that with. Now, in addition to that, I'll supplement with, when I'm in person with someone, I want to carve out time for a proper catch up and less structured, less timely, and just more of building a relationship with a human.

(00:17:53):
But I actually find that having that common .. It's almost a barbell approach where it's like if you're going to spend time with somebody in a freeform way, actually do it in a high quality, not forced weekly ritual way. Go for a longer lunch or coffee walk or whatever in person when you can. Maybe that's a once every month or two kind of thing. And then the in-betweens are either topical, so we do have standing meetings for ... Now, we have a weekly basically sprint check-in on all of our AI execution stuff, which now is half the company or half the EPD org is working on AI capabilities.

(00:18:29):
We're trying to ship very quickly, like I basically want to always ask the question, how would an AI native company, like a cursor or windsurf, et cetera, how would they execute? And are we executing as fast as them and taking advantage of all the new stuff as well as them? So bringing that level of intensity and urgency to how I spend my time within, that's been the biggest shift for me.

Lenny Rachitsky (00:18:55):
What's a change you've made to help the company move faster and match that sort of pace?

Howie Liu (00:19:01):
Yeah. I mean, we did do a reorg of the EPD org. So before we had ... we've gone through a few different reorgs over the past, call it, four years. The original state as we just proliferated, I think by default or incrementally, was that we had a bunch of groups that were each responsible for a feature or a surface area. So there was a group responsible for search within our table, and there was a group responsible for mobile experience and so on and so forth. And that has its benefits. Obviously, that team can go and get really ramped up on that part of the code base, that part of the product.

(00:19:36):
But it has the disadvantage of yeah, you tend to think incrementally when everyone's remit is actually a feature that they incrementally improve by definition as opposed to thinking about a mission or a outcome goal that might need to coordinate dramatic changes across a wider set of surface areas instead of just each one incrementally improving. And so, we reorged initially to basically different business units effectively. So I know Airbnb has done the functional to GM back, et cetera. This was more like saying, "Look, we have an enterprise business" and them MO there is more about scalability.

(00:20:19):
Can we support the larger scale data sets and use cases? Do you have the core capabilities needed to be able to push out an app to maybe 10,000 seats or 20,000 seats for product operations? A lot of architecture, a lot of scale, that kind of work. We would have, what we call the teams filler, which is more about self-serve, kind of the product UX, how easy it is to adopt the product on board, share, do all the kind of basic functionality. An AI pillar, solutions pillar, and basically infra. And what we found though with that approach is that there was still ... there was more kind of holistic bets being made.

(00:20:58):
So the team's pillar could think not just about one feature, but the overall onboarding experience where really about Nuxt in a way that touched multiple parts of the product, but it still felt like it wasn't ... Especially as we started to execute more on AI stuff, it wasn't allowing us to aggressively and quickly move as a AI native company would. I mean, when you look at the cursors of the world, they're shipping major new stuff every week. And it's not like, "Oh, well we have this separate roadmap for enterprise, we have this roadmap for this group."

(00:21:33):
And it just feels like one cohesive product that's shipping at a breakneck pace. So we did this recent reorg where now we have what I call the fast thinking group, which officially is called AI platform, but it really means we want to just ship a bunch of new capabilities on a near weekly basis. And each of them should be truly awesome value. You should drop your jaw, how awesome it is to use this new capability in Airtable. And then separately, we have the slow thinking group, and that's not meant to be better or worse. It's literally like you need fast and slow thinking in the common sense to operate as a human.

Lenny Rachitsky (00:22:12):
I have that book behind me.

Howie Liu (00:22:14):
Yeah, I love that book. But slow thinking it's like, it's just a different mode of planning and executing, right? It's like more deliberate that require more premeditation. We can't just ship a new piece of infrastructure that has a lot of data complexity like our data store HyperDB that now can handle multi-hundred million record data sets. That's not something you ship in a week in a hacky prototype. So we now have these two separate parts of the company, and I actually think what's really cool is they actually compliment each other very well, right?

(00:22:46):
Because the fast execution, the AI stuff, that creates the top of funnel excitement that also inspires new use cases and new users to come to Airtable, including in large enterprise, right? Enterprises can use this stuff too. It's not just like a SMB thing, but the slow thinking basically allows those initial seeds of adoption to Sprout and grow into much larger deployments. Whereas I think a lot of the challenge for many of the AI native companies I've seen is that they could have a very wide top of funnel, like get all of this AI, tourist traffic.

(00:23:19):
A lot of interest, a lot of early usage, but then sometimes the challenge is how do you turn that into more durable growth and get each of those adoption seeds to retain and expand over time.

Lenny Rachitsky (00:23:33):
That is super cool. I've never heard of this way of structuring teams, the fast thinking, thinking fast, thinking slow, the Kahneman. It's so interesting for the fast thinking team, do you find there's specific archetypes of people that are successful there? Is it a lot of bringing in new people that are not just used to the way of working at our table? What do you find?

Howie Liu (00:23:52):
We have a mix. So we brought in ... I mean, we're always hiring, right? There was never a point in the company's life where we stopped hiring. And candidly, even when we had to do two rifts, that's significantly reduced our head count. We had just way too quickly grown and overscaled the business at a certain point. But even when we did our rifts, we were still actively recruiting and hiring in ... I mean every major department, but especially in EPD, because it's always been my belief that it would be arrogant to say that we have all the people we ever need already in the roster today, right?

(00:24:29):
We're always going to need to find new, fresh perspectives, new skillsets, et cetera. And so, we've continued to hire ... I think we've learned as we've gone along of what is the ideal type of hire, and we've done some actual hires and learned from that as well. But I think the fast thinking part, it really just requires a lot of ... Somebody who's able to operate with a lot of autonomy, who's entrepreneurial in nature. Now, it doesn't mean they have to literally be a former founder. I know some companies are, like Rippling for instance, does a lot of actual acquisitions and gets actual founders into the company.

(00:25:04):
We found that that's great and we've done some of that as well. But also there are some really, really capable people who we didn't literally have to acquire in, and yet, they're just able to think full stack about the problem and the user experience. Problem, not just meaning the technical layers of the problem, but also, what is the wow factor we're trying to create. So tangibly we're doing this new thing that's about to ship, where not only can you describe the app you want to build and then iterate on it with our conversational agent Omni.

(00:25:41):
And it builds it with the existing air table platform capabilities, but we're also giving it the ability to actually do code gen, to extend those apps with really final mile very bespoke functionality or visuals. So you could say, "Hey, generate me a very, very specific type of map view with this kind of heat mapping and this kind of icons and ..."

Howie Liu (00:26:00):
It's kind of like heat mapping and this kind of icons. And when you click it, do this. And that's a capability that there's so much ambiguity in some of the design decisions around it. And you have to blend that design thinking with some of the technical constraints of what can the AI models actually one shot effectively?

(00:26:21):
And if not, how do you add in the right human workflow for approval and review, and the reprompting and so on? So just so many different design decisions, and you need somebody who can really think full-stack about that kind of product and is not overwhelmed by that kind of open-endedness, but relishes in it.

Lenny Rachitsky (00:26:38):
I was actually playing with it before we started chatting. I made a really cute startup CRM.

Howie Liu (00:26:43):
Oh, that's awesome.

Lenny Rachitsky (00:26:43):
Yeah, started talking Omni over here. It's like the colors are beautiful-

Howie Liu (00:26:47):
[inaudible 00:26:47].

Lenny Rachitsky (00:26:47):
... so that's what's standing out to me right now.

Howie Liu (00:26:49):
[inaudible 00:26:49] there is...

Lenny Rachitsky (00:26:50):
Yeah.

Howie Liu (00:26:50):
I will say just as a note, I consider myself at my core a product UX person. That's my passion. And everything else I've had to learn to run this company is almost like what was a necessary part of the journey. But my real passion is thinking about product UX. And I think of UX in a deeper sense than just the cosmetic design. What you could put into a framer kind of prototype. I think of it as literally what should this product do and how should it represent that and behave for the user? That is the product, in my opinion, right. And of course, then you have to figure out technically what's possible and how to implement it.

(00:27:36):
But I think to me what's under executed today in the world of AI products is there's so many awesome capabilities of AI, and most of them are really under merchandise, and there's very poor, actually, visual or otherwise metaphors or affordances given to users to help represent or understand what those underlying capabilities are. I mean, ChatGPT obviously extremely successful product, so not knocking it at all, but you come in and you just get this completely blank chat box by default, and now they have suggestions underneath and so on.

(00:28:13):
But the product UX part of me is just craving more visual metaphors or colors or some kind of use the canvas of a web interface and all the richness interaction you create there to better represent or show all the different things that you can do with the underlying model, right. And so that's something we've tried to do with Airtable, is show all of the different states and use colors even to play those up.

Lenny Rachitsky (00:28:44):
It's interesting how much of this connects with I just had Nick Turley on the podcast. He's head of ChatGPT at OpenAI, and he had these two really interesting insights that resonate directly with what you're describing. One is he has this concept of whenever something is being worked on, he's always asking, " Is this maximally accelerated? How do we move faster? If this is important, what would allow us to move faster?"

Howie Liu (00:29:06):
Yeah.

Lenny Rachitsky (00:29:06):
And I love that that's one of the themes that's coming up as you talk, is just this creating this very clear sense of speed. And you even call it the fast-thinking team, like, "You are going to move fast." And then the other one is just this insight that with AI, you often don't know what it can do and what people want to do with it until it's out. So there's this need to get it out, and that'll tell you what it should be.

Howie Liu (00:29:29):
I couldn't agree more with both of those, and particularly on the second point, I think it's interesting. Clearly, there have been companies that have both been successful in PLG and more sales-led distribution for AI products. The most notable ones I can think of are Palantir with their AIP deployments. That's obviously very sales-led. You're not PLG into a Palantir deployment. But even companies like Harvey and so on, they're doing very well. And it's primarily, from what I understand, sales-led.

(00:29:59):
You're not self- serving into a Harvey instance at a law firm. And yet, to me, the best way to get AI value out there is experientially, right. And so you can kind of get that in a sales motion. You can show a demo. Maybe you can do a POC, but it's so much more powerful when you just open up the doors and say, "Anyone who wants to come and sign up and trial this product can." And I think to me, it's a real proof point that ChatGPT is arguably the most successful kind of PLG product of all time, just in terms of sheer scale of users. Like they announced 700 million... Is it MAUs or week... I think it's actually-

Lenny Rachitsky (00:30:41):
Weekly active users.

Howie Liu (00:30:41):
Weekly.

Lenny Rachitsky (00:30:42):
10% of humans on earth use it-

Howie Liu (00:30:43):
That's insane.

Lenny Rachitsky (00:30:44):
... weekly.

Howie Liu (00:30:45):
That's insane. In how many years? A few years.

Lenny Rachitsky (00:30:48):
Three years. Under three years.

Howie Liu (00:30:49):
Yeah. So I mean, literally, that is just the most insane ramp curve. And I don't think they would've gotten there if you couldn't just come in and literally try the product out. And as a little bit of a rebuttal of the point I made earlier where I think ChatGPT doesn't do a ton right now, and even earlier they did even less to expose all the different ways you could use it, but they just made it so frictionless to just try it for yourself that you as a user could come in and just literally ask it anything and see how it did. And of course, people in the early days tried to stump it and showed, "Oh look, see, it's not that smart. It doesn't answer this hard question really well."

(00:31:26):
But clearly, the magical nature of it still appealed to you enough. Everybody used it. And so I think I do have a view. We've gone through that whole arc of we started PLG. I'd like to think Airtable was one of the PLG darlings of our era. And anyway, I started moving up market and doing more sales execution, although that was still always on top of usually PLG within an enterprise, but we started doing more and more sales execution. We still have that. That's still really important for our business. But I also think, me personally, one of my goals is to shift my attention back into that kind of builder-led adoption and literally showing in the product experientially, not telling in a deck, the value that you can get from AI and Airtable.

(00:32:20):
I think that's so key, and it's [inaudible 00:32:23], but it's also more than that. It's not just literally how do you onboard somebody into the product. It's literally thinking about the entire product experience itself, right. And in our case, we just made the entire product experience AI-centric. It used to be that we had kind of this secondary thing that you could ask questions to the assistant sidebar. We now made our agent the default way of doing everything in Airtable, and it's now the Airtable app, as you know, it is almost like an artifact that's manipulated by and can be tool used by the agent.

Lenny Rachitsky (00:32:58):
Let me follow that thread. So if you go to Airtable.com today, it looks like basically all the other AI app building sites. Now it's just tell me what you want to build. Thoughts on that, as just a thing everyone's starting to do is there... what do you think comes next? Is this... Is it working well?

Howie Liu (00:33:15):
There's clearly an incredible magic to vibe coding and app building with AI. And this is actually a prime illustration in my view of that concept we talked about a second ago, which is as capabilities of these underlying models evolve, the form factor in the product UX also needs to evolve with it. And so the earliest models, like the kind of original ChatGPT, like GPT-3.5 kind of era models were not nearly as smart as the current models. And so you couldn't really ask it to one shot a more complicated chunk of code, or certainly not like a full stack app, and expect it to work.

(00:33:56):
And so the right form factor for leveraging those models in a software creation context was GitHub Copilot, right. It's like auto-complete a few lines of code at a time. But you couldn't chat to it and tell it, "Build me this entire app from scratch." And I think that as the models got better and better, you saw that the new form factors emerge. I think Cursor did a great job of being an early pioneer of this more age agentic way of leveraging the models to do more complex things and generate more larger chunks of code.

(00:34:27):
And now with Composer, you can literally just go into Cursor and build an app from scratch, build me a 3D shooter game from scratch, and just watch it go and create all the files and fill out each file, and then the thing actually runs some of the time. And so to me, this is where the world is going. The models are clearly getting smarter. And if you think about the original vision of Airtable, it was always about democratizing software creation. We just strongly believed that the number of people who use apps far outweighs the number of people who can actually build their own or manipulate apps and harness custom software to their advantage.

Lenny Rachitsky (00:35:08):
That sounds very familiar, very familiar these days.

Howie Liu (00:35:10):
Yeah, exactly. And so I think this is, it's a different means to the same end. And so it's almost like we have to lean into this because if we started Airtable today, this is what we would be all in on. Now I think that the advantage that we have, and I do think you have to be realistic to yourself, especially as a company that predates GenAI and now has to find your new footing in the AI landscape. You can't fool yourself and just say like, "Okay, I'm going to throw in some AI stuff on the landing... on the marketing site, put in a couple AI features, and call it a day."

(00:35:43):
I think you actually have to take a clean slate approach to saying, "How would our mission best be expressed? If you were literally founding a new company from scratch with the same mission, how would you execute on that mission using a fully AI native approach?" And then, by the way, do you have useful building blocks that you can leverage from your existing product and your existing business, or are you literally worse off having this legacy asset versus starting something from scratch? And I don't think the answer is always yes or no. I think it just depends on the product.

(00:36:19):
And if you can't really introspect and say, "Look, I think I'm better off doing this with the pieces that I have for my existing business and product," then I think you should sell. You should find a buyer for that company and then go. And if you really care about this mission, go and start the next carnation of it. In my case, I really thought about this and really feel strongly that the building blocks that we have, these no code components, actually do allow us to execute better on this vision than if I had to start from scratch.

(00:36:50):
Meaning the problem with vibe coding, especially if we're building business apps... So I should clarify that we want to democratize software creation, but specifically, we are focused on business apps. We're not trying to be the platform where you create a cool viral consumer game. This is for like your CRM, right. Or if you want to build an inventory management system as a small restaurant or a lawyer trying to build a case management system, that's what we've always been focused on. And I think in this AI-native world, clearly, you should be able to generate those apps agentically.

(00:37:24):
And yet if you have an agent that has to generate every single bit of that app from scratch, from code, it's going to be very unreliable. There's going to be bugs. There's going to be data and security issues. And then you're also going to have a context collapse, as it just cannot manage all of the code that it's written, basically, as the app gets more and more complex. And what we actually have are basically these primitives that the agent can manipulate and use without having to literally write the code from scratch to represent, "Here's a beautiful crud interface on top of the data layer.

(00:37:57):
Ours is real-time and collaborative, and really rich, and has collaboration on it. And by the way, here's all these other view types and a layout engine for a custom interface, a layout, or automations and business logic." And so it's almost like in programming terms, the Airtable pieces in our Lego kit today can be used by this agent as almost like a more expressive DSL, like a domain-specific language to build business apps instead of literally having to write everything down to the SQL and HTML and JavaScript to build every part of that app from scratch.

(00:38:31):
And so if we can combine the best of both worlds, we have these very reliable, high-quality Lego pieces. Now, an agent can go and assemble them for you instead of you just using the GUI to do that. And by the way, if you do want to fall back to the GUI, there's a really great kind of way for the non-technical user to still understand and participate in what's going on. Whereas if you're not technical, you can't inspect the code underneath a v0 or Lovable or Revolut app, right.

(00:38:58):
It's just kind of opaque to you. And if you can't re- prop it to get what you want, you're kind of stuck. This is much more akin to a developer using Cursor can generate lots of code, but then can still drop back to the IDE to edit and manipulate it to the final production-ready state. So that's kind of the play that we're making. And if I didn't fully and truly believe we have a better shot at doing it with our existing product, I wouldn't be running this company in its form today.

Lenny Rachitsky (00:39:25):
I'm talking to a lot of founders that are going through the journey are going on, which is, "We've had a business for a decade, AI emerged, and wow, we got to figure out something that works... that could work even better." And so I'm trying to pull out the threads that are consistently working across these journeys because I think a lot of companies are trying to figure this out. So one that you just touched on is just if you were to start today, what will you do?

(00:39:48):
What would that business be? Plus, how can... do we have an unfair advantage with the thing we've done in the past? That feels like an important ingredient. And then the other... circling back to stuff you've shared already, there's just creating a sense of urgency and pace and getting people to understand this is how things move in AI, and we need to create this fast-thinking team. I love that metaphor in framing.

(00:40:11):
And then there's the point you made about just talking to AI regularly as the founder feels like an important element, just like to truly be this ICCO talking to AI, working with AI regularly. Just on that note a little bit more, just to give people a sense of what this looks like day to day. So you're talking to Omni all day trying to and undertook... flex the power of what you can do and iterate on it. Is there anything else you're doing day to day that helps you figure out what to do for the business?

Howie Liu (00:40:38):
One, I try to use as many different AI products, including not Airtable, as I can, and both literally for the novelty factor and just some new cool demo comes out. Like Runway release their immersive world engine, and so I'm going to go try it out. When Sesame AI put out their cool interactive voice chat demo, I tried that out because even though we don't have a direct and near-term need for really realistic and interruptible voice mode where it's not as core to our capabilities, I just want to understand and get a feel for everything that's out there.

(00:41:23):
And I try to invent little, almost like side projects of my own, to have a real reason to use these products. Like, "Oh, cool. What if I were to take... What if I were to try to create a funny little short... a funny video short using a combination of HeyGen avatars with a script, like a comical script generated by AI? And maybe it'll be on an interesting topic. So I'll do deep research on the topic with ChatGPT and pull together the results, have it compose kind of a little dialogue.

Lenny Rachitsky (00:41:58):
Did you actually do this? Is there something you made?

Howie Liu (00:42:00):
Yeah. That's literally an example of something, just a fun weekend project. And to be honest, these things only take you an hour if you become kind of pretty proficient with using the products. They're all so easy to use. You can literally do the deep research thing, kick off query, make a coffee, come back in 20 minutes. Okay, let me prompt it to generate me some dialogue. It's a little bit like what NotebookLM does for you out of the box, but sometimes I like to just do it myself. And then, okay, let me take the script and cut it up and turn it into a HeyGen avatar and then download the video and play it.

(00:42:32):
And just for fun. I'm not trying to make that into an actual YouTube video business. But I think coming up with these different fun weekend projects is a really useful construct to force myself to actually try these products in a more than just a Twitch click way. And what it gives me is, A, it's not just understanding the models, which is also very, very important, right. GPT-5 came out yesterday, and playing around with it a bunch just on a variety of different personal use cases, but there's a difference between just understanding the model but then also understanding the product form factors in which they can be placed, right.

(00:43:15):
Meaning when you apply the model in a more structured way, when you apply the model with different tool calling than maybe what ChatGPT has in its out-of-the-box form, when you apply it with a more agentic workflow, again, that might be different from what ChatGPT gives you out-of-the-box, that's when you kind of learn you really get to inspire yourself on what are the product's form factors that these new models can take. And plus, by the way, I find it to be really fun. There is to me a delight and entertainment value to just using AI, period, because A, it's not perfectly predictable.

(00:43:57):
So I think the element of you're not quite sure what you're going to get. It's like a box of chocolates. And B, it always blows my mind just to think about, "Wow, five years ago we didn't have any of this stuff." AI was like, okay, it's like we can do predictive analytics. There's some basically very advanced kind of regressions that we could run with AI, but it looked nothing like this in its current form, and it's just actually super fun, in my opinion, to get to play around with all the different types of products that come out.

(00:44:33):
I think that is a big part of it because on the point about the pace of the world moving so much faster in AI than any other landscape in SaaS, in the mature SaaS era, it was important to study your competition. If you were building a SaaS company, you'd be crazy not to follow Salesforce every year and see what the major releases they're putting out are, or ServiceNow, or so on.

(00:45:03):
This is the equivalent of that, but there's major new releases and products and so on every week, not every year. And so I just think you have to say abreast of all... of it all and combining this with our point earlier of a lot of this has to be experienced, not just read. You can't just read the write-up on TechCrunch or even a tweet about a new capability. You kind of have to try it to really get a sense of what it is.

Lenny Rachitsky (00:45:33):
Today's episode is brought to you by Anthropic, the team behind Claude. I use Claude at least 10 times a day. I use it for researching my podcast guests, for brainstorming title ideas for both my podcast and my newsletter, for getting feedback on my writing, and all kinds of stuff.

(00:45:49):
Just last week, I was preparing for an interview with a very fancy guest, and I had Claude tell me what are all the questions that other podcast hosts have asked this guest so that I don't ask them these questions. How much time do you spend every week trying to synthesize all of your user research insights, support tickets, sales calls, experiment results, and competitive intel? Claude can handle incredibly complex multistep work.

(00:46:13):
You can throw a hundred-page strategy document at it and ask it for insights, or you can dump all your user research and ask it to find patterns. With Claude 4 and the new integrations, including Claude 4 Opus, the world's best coding model, you get voice conversations, advanced research capabilities, direct Google Workspace integration, and now MCP connections to your custom tools and data sources.

(00:46:34):
Claude just becomes part of your workflow. If you want to try it out, get started at Claude.ai/Lenny. And using this link, you get an incredible 50% off your first three months of the pro plan. That's Claude.ai/Lenny. For people that work for you across Airtable, say the product team, PMs, maybe engineers, designers, how have you adjusted what you expect of them to help them be successful in this new world?

Howie Liu (00:47:02):
One is really, really, really stressing this idea of go play with this stuff. And I mean, when I say play, I really mean play in the psychological sense of there's a difference when you go in and you're kind of just trying to check the box and get a job done. There's a difference when you come in with a curiosity and you're kind of exploring, right. And it's both more fun and energizing, but also, I think you learn more through that. And so I've really tried to stress the value of play with these AI products.

(00:47:36):
And I kind of try to lead by example, by literally going and sharing out links or screenshots of the things that I'm doing in these various products. So, as an example, I will go into one of the prototyping tools and show, "Hey, I built a marketing landing page for this new capability we're launching." I created a landing page for it in Replit, let's say, and now I'm sharing that link. Instead of what typically we would've done in the past is like, okay, we're going to write a doc about it and then share the doc, I'm just going to show you an actual landing page with visuals and everything in there.

(00:48:20):
Or I'll share the actual link to my deep research reports. Or instead of me writing a perfect memo on a topic, I'll actually just prompt my way into getting a chat thread or a chat output that basically covers all the content that I care about and maybe even ask it to, "Okay, summarize this all into a final memo output," and then intentionally share that rather than expose the fact that I'm using AI in this way and here's literally how I'm prompting it so you can follow along as well.

(00:48:49):
But really trying to encourage everyone to go and just play with these products. And I've even said, "Look, if anyone wants to just literally block out a day or frankly even a week and have the ultimate excuse, you could use... you could say that I told you to do it, right. If you want to cancel all your meetings for a day or for an entire week and just go play around with every product, AI product that you can find that you think could be relevant to Airtable, go do it. Period. So I think that's the most important thing is this play, this experimentation.

(00:49:25):
I think there's also a lot of other kind of shifts in how we execute prototypes over decks. I want to see actual interactive demos because, again, it's hard to... In a deck or in a PRD, you could say, "Okay. Well, we're going to make Omni really good at handling this kind of app building." Okay, those are just words. The real proof is in the pudding of like, "Okay, let me try it out on a few realistic prompts that I can imagine."

(00:49:49):
And in a demo, in a real prototype, you can instantly try it out on unrealistic rather than golden pathy scenarios and see how it feels too. Does it feel too slow? Do we need to expose more of the reasoning or steps that are happening behind the scenes? Create a progress bar or something like that. But it's really hard to get that feel of the product with anything but a functional prototype that really does, in an open-end way, use the AI to do whatever you put in.

(00:50:24):
So I think it's more like a experimentation playground it feels like how we need to execute, versus I think, in the past, it sometimes felt like a more deterministic resourcing and kind of timelines view of execution. We're going to put this many people on this problem, and this is the eight-week timeline to this milestone, and then we're going to ship in a quarter from now. And I think now the whole thing is just a lot more experimentation and iteration-driven.

Lenny Rachitsky (00:50:56):
Of the different functions on a product team, PM, engineering design, who has had the most success being more productive with these tools, and how do you think this will impact each of these three functions over time?

Howie Liu (00:51:07):
What I found is that it really does become more about individual attitude and maybe some polymathism. There's a strong advantage to any of those three roles who can kind of cross over into the other two, like the hybrid unicorn types.

(00:51:26):
So if you're a designer who can be just technical enough to kind of be dangerous and understand a little bit of how these models work and how does tool calling work and all of this stuff, then you can actually design a concept or even prototype a concept, including in these prototyping tools that's much more interesting and maybe realistic than if you're just stuck in the flat like let me put something in a static design concept because I think designs have to be more interactive. The whole... The value of the product and the [inaudible 00:52:04]-

Howie Liu (00:52:01):
... the value of the product and the product functionality is in the interaction of it, right? Think about the design of Chachi Petite. Again, it's the most basic design you could possibly imagine. The real design actually is happening underneath the hood in how it responds to different queries and what happens after you fire off a prompt, right? So I think I found that there are people within each of these functions, there are engineers who are very good at thinking about product and experience and can go and prototype out the whole thing. They're designers who can do the same. Even if they can't literally code, they can prototype something out literally using a prototyping tool.

(00:52:42):
I think that's where AI tooling is also giving more advantage to people who can think in this way by equipping them with an alternative to actually having to go through the long hoops of learning CS, right? Then PMs as well. I think there are some PMs who are really getting into the technical details and studying up on how does this stuff work and actually getting hands-on, rather than seeing the role as writing documents, writing PRDs.

Lenny Rachitsky (00:53:08):
Do you see one of these roles, I don't know, being more in trouble than others, just like you need fewer of these people in the future potentially?

Howie Liu (00:53:16):
I think overall you can get more done with fewer people, and that's not to say we want to go and make the team smaller, but rather ... the really cool thing for us and I think a lot of other companies is it's not like you have a finite set of things you need to do and execute on from a product standpoint, and okay, now I can do that with a 10th of people. I mean, you could do that in a lot of cases, but for us, maybe it's also because we're a very meta product, right? We are the app platform with which you can build now any AI app with AI, right? The apps themselves leverage AI capabilities at runtime, whether it's to generate imagery for a creative production workflow or leveraging deep research, or AI-based crawling of the web to search for companies that match a certain criteria for your Dealflow app or something like that.

(00:54:10):
We can effectively leverage all of these other AI capabilities in this app platform, because by definition we're enabling our customers to build apps that have this wide range of AI capabilities. But because of that, it's like we have a almost infinite set of possible AI capabilities that we could execute on, right? I'm always telling the team like, "Look, the great news is it's like we have all these fruit trees and there's so many crazy low-hanging fruit, and you've got literally massive watermelons literally sitting on the ground and all you have to do is walk over 20 feet and pick it up instead of having to climb the really tall coconut tree to grab a hard coconut from 50 feet up. So there's so many watermelons on the ground, just go out and start finding the biggest ones and attacking those, right?"

(00:55:03):
What that means is that if we can build this culture, and I do think it's a learnable way of operating, I really like to believe in the growth potential of any human and any individual. I think if you really have a growth mindset, and that's why one of our most important core values is growth mindset, right? If you really have that growth mindset, I think especially if you're willing to put in the nights and weekends hours, or in my case I'm literally telling people like, take a full day off, take a full week off and learn this stuff, you can become more fluent in this way. I think then what we get is a team that can just go and work on more things in a much more leveraged and fast way, right?

(00:55:48):
So, I like to think people who are willing to jump on the train are just going to become more and more effective. It's not like, oh, as a PM my role is becoming entirely irrelevant, right? No, it means that as a PM you need to start looking more like a hybrid PM prototyper who has some good design sensibilities. By the way, I think some of the best eng PM and design cultures respectively over the past even few decades have always been multidisciplinary in nature, right? The original PM spec at Google required the PMs to actually be somewhat technical so they could understand the engineering limitations of the product designs they wanted to make, and they had to be kind of designy, right?

(00:56:33):
I remember my co-founder, Andrew, when he was in the APM program was always reading books about design, even down to visual design and color theory and that kind of thing, right? So I think it's just a reminder that designers as well, some of the best designers through designer to Apple, including hardware designer, you have to understand some of the technical capabilities of how this stuff works, right? If you're an engineer, I think some of the best engineers and maybe Stripe always had a very good engineering culture of engineers who could think about the product and business requirements. In fact, on any given product group, at Stripe my understanding is that the DRI isn't always the PM as is traditionally the case in that triangle. Sometimes it's actually the engineer who's taking the product lead and saying, this is what we need to build.

Lenny Rachitsky (00:57:24):
So, what I'm hearing is essentially the trend across product engineering design is each of those functions needs to get good at one of the other functions at least.

Howie Liu (00:57:35):
Yeah.

Lenny Rachitsky (00:57:35):
Ideally you can do them all, but if you can just do one additional, so a PM becomes better at design, an engineer becomes better at product management.

Howie Liu (00:57:43):
Well, I would actually go further and say I think you need to get decently good at all three. There's just a minimum baseline of if you're any one of those roles, you need to be minimally good at the other two, and then you can go deeper into your own specialty, right? You could be a designer who's really good at thinking about UX and interaction design, and then just good enough to be dangerous on thinking about what's technically possible and what is the product story around this feature.

Lenny Rachitsky (00:58:17):
I love that. To do that, one piece of advice that comes up again and again in what you've been describing is use the tools constantly to see what's possible, and that will teach you a lot of these things.

Howie Liu (00:58:28):
I think, well, use the tools gives you exposure to what's possible, right? It's kind of like if you wanted to be a great industrial designer, and let's say, I mean, the chair is the ultimate hello world of industrial design, it's the canonical design object, you wouldn't just sit there in a vacuum with no familiarity with the materials that you can use, plywood, steel, whatever, or existing form factors of chairs trying to invent the world's best chair in a vacuum, right? You should go and first do a study of all of the best chairs out there today. Go look at an Eames chair, sit in it and try to examine it to reverse engineer how it was made, and just look at the prior art for that type of product. That's how I see the go out and play with these products, and also, I think actually going and designing or implementing or executing is the best practice.

(00:59:21):
So you can't just only go and look at other people's chairs, eventually you have to go and actually try building your own and then try building another one and another one and another one. So, I think that's where ... when I think about how I hone my own product UX sensibilities, I never ... and at that time that I was in school and then learning about this stuff, there wasn't really any good curriculum for UX, right? It's not like there were great college classes to learn product UX. I mean, even CS was very academic in nature at that time, it wasn't applied software engineering, like build an app or whatever. Maybe now at some of the schools like Stanford, MIT, they have actually UXy type courses, but it's still a rarity for most people to have access to that.

(01:00:03):
So, the way I learned all of my product sensibilities was just trial and error and also using and studying other products, and then going and trying to build my own weekend project ideas, right? Oh, I want to build a Yelp style app with a map view and then also a list view, and I want it so that when you pan around in the map for it to automatically update the list view. Maybe there's some UX improvements I can make on top of that, but I can also test my technical skills to figure out which parts of this are hard to implement and how do you make it work, and what are some of the design changes or affordances that you can use to map to the technical possibilities.

Lenny Rachitsky (01:00:43):
To do that, I loved your piece of advice, which I forgot to double down on, which I also find really powerful. The best tip there is find something to actually build that is useful to you and fun. Pick a project that's like, okay, this would be fun to do. Have a problem you're solving that forces you to actually do this thing.

Howie Liu (01:01:00):
For sure. Look, I think that can be night and weekend projects, it can also be the daytime job projects, right? I mean, I am basically telling our teams on the AI platform group especially, "Look, in that low hanging fruit metaphor, it's like I'm not being prescriptive with you on which watermelons you should pick, but you should go ..." We do have different pods within that group, but one of them for instance is what we call the field agents team and they're responsible for the agents that work within your app. So this is not the agent that builds your app, but these agents that run on a customer's behalf to do web research on your customers, or they can go and analyze a document and in the future maybe do things like actually generate a prototype of a feature from a PRD or from a feature idea.

(01:01:52):
I'm telling them, "Look, there's a almost infinite number of superpowers you can give these field agents. I'm not going to tell you which specifically to do. Now you can ask me to weigh in for sure, but you should go and just experiment and prototype a few different directions we could go." What if you prototype what it would look like to have a deep research implementation in field agents, so that for any given row of data, let's say in your case it's podcast guests, you can just click a button or click a button en masse across every speaker you have lined up to do deep research powered by ChatGPT's own deep research on each of the speakers and have them all laid out side by side in this table, right? Go prototype that and see how it feels and looks like. So I think some of this stuff can also be in your daytime job, especially if that daytime job is literally to go and build AI functionality.

Lenny Rachitsky (01:02:46):
I actually tried to do exactly that. The problem I ran into, I wonder if it's changed, is there's no API for ChatGPT deep research yet as far as I know.

Howie Liu (01:02:55):
There is now, there is now.

Lenny Rachitsky (01:02:56):
There is, there we go.

Howie Liu (01:02:58):
Sometimes it ends up being ... and I think they only recently exposed it. It ends up being something on the order of a dollar plus per research call, which-

Lenny Rachitsky (01:03:05):
What a deal.

Howie Liu (01:03:05):
... I mean, again, exactly. I mean, some people would say, oh my god, that's so expensive, and you rack up 50 of those, you've cost $50 a month. I think it's like, well, it just saved you hours of research by a human.

Lenny Rachitsky (01:03:16):
Not only that, I actually have a researcher that I pay to give me background on guests that was four or 500 bucks and the dollar sounds great. I've been doing this-

Howie Liu (01:03:28):
[inaudible 01:03:28]

Lenny Rachitsky (01:03:28):
... I've been doing this manually.

Howie Liu (01:03:29):
If he was being smart he would be using deep research and they just collected [inaudible 01:03:33]

Lenny Rachitsky (01:03:33):
They might be. They might just be. Oh, man. Okay, there's one more skill I wanted to talk about real quick. This comes up a lot in these conversations is evals.

Howie Liu (01:03:43):
Okay.

Lenny Rachitsky (01:03:43):
The power of getting good at evals, I know that's something you value highly. Talk about just why you think this is something people need to get good at.

Howie Liu (01:03:50):
Yeah, and I listened to your episodes with [inaudible 01:03:54] and Mike who talked about this. I think it's interesting that both heads of OpenAI and Anthropic have converged on this point. I mean, look, I think I would add a slightly different or additive take though, which is I think for a completely novel product experience or form factor, you should actually not start with evals and you should start with vibes, right? Meaning you need to go and just test in a much more open-ended way, like, does this even work in kind of a broad sense?

(01:04:28):
So as an example, for our custom code generation capability, instead of defining evals that get repeatably tested as you vary the prompt or the model or the agentic workflow used to generate these outputs, and you have to define what does good look like by definition for the eval, I would first start with a much more open-ended and ad hoc style of just throw stuff against the wall, try different prompts and see how well it does.

(01:05:01):
To me, evals are more useful, A, once you've converged on the basic scaffold of the form factor and you kind of know what are the use cases you want it to work well for and what you want to test against it. Whereas in the early days, especially if your product market fit finding either for an entirely new company or for a pretty dramatically new or bold new capability that doesn't really have ... it's not an incremental improvement on something that exists in Airtable today, I think you have to just be a little bit more creative initially and throwing stuff at it, seeing what works to understand, okay, let's use an example, we're implementing this new capability that can use basically a long-running AI crawler agent that goes and researches the web for a specific type of object or entity, right?

(01:05:55):
So it's similar to deep research, but what it actually does is instead of outputting a report, it's actually going and compiling a list of things. The things could be companies or people or anything else, right? Find me every Marvel movie ever made, find me every DC Comics spin-off series, literally anything. You have to go in and first just try out a bunch of random ... use your own brain to think of what's the range of use cases I can test this against, right? Then you get back some results and you're like, okay, well, it's clear that where it does really well are these types of searches, people and companies with this kind of parameter.

(01:06:42):
I think to me, evals are useful once you have a sense of what is that cluster of useful use cases, you can start then more programmatically measuring the changes that you're making to improve the output for that, right? But by that point, you've probably already scoped the product and maybe the way we would merchandise it in Airtable is not a completely open-ended capability, but hey, here's a specific capability that can research one of these X number of entity types including people and companies, and here's even the filter conditions or criteria that are more explicit that you can define to give it the prompting to search for that thing, right?

(01:07:25):
But I kind of think it's more useful as a way to iterate your way to improvement, and you can start really testing stuff empirically, right? You can A/B test, especially if you have the scale of a really large product like Anthropic or OpenAI, you can just test everything and see like, oh, this model actually performs better than this one, this prompt performs better than this one, but I think early on you don't have that luxury and you're in a much more open-ended discovery process.

Lenny Rachitsky (01:07:51):
That is very wise, evals could constrain you too early. I think about just the Double Diamond, I don't know, IDO framework of be divergent first, and then converge and then maybe-

Howie Liu (01:08:01):
Yeah. Yeah, exactly. I hadn't heard that before, but that completely resonates.

Lenny Rachitsky (01:08:06):
Okay, let me try to reflect back some of the advice I've been hearing about how to shift a company to be successful in this new world, and let me see if I'm missing anything that you think is really important. So, one is there's this sense of just reset the expectations on pace and urgency and help people understand in AI things move incredibly fast, this is how we need to operate. Then there's also a piece of get stuff out so that you can learn how people use it and what it's capable of versus polishing it endlessly. Forcing people almost ... I don't know if forcing's the right word, but encouraging people to play with the latest stuff and giving them a chance to take days off or block out calendars, cancel meetings, just stay on top of this stuff to play as you talked about it. Then sharing things they've learned, get the vibes of what's possible.

Howie Liu (01:08:54):
Yeah.

Lenny Rachitsky (01:08:55):
There's also this idea of just rethink, okay, if we were just start today in this world, what would we do to achieve the same mission we are trying to achieve? Ideally it leverages this unfair advantage we have with things we've been working on for a long time. Then there's just talk to AI constantly every hour as you described.

Howie Liu (01:09:16):
For sure. Yeah, multiple times an hour, if possible.

Lenny Rachitsky (01:09:16):
Multiple times an hour, it keeps going up. Is there anything else that I missed there that you're like, you need to do this too to have a chance?

Howie Liu (01:09:25):
I think just to really, really try to break down role silos, and I think that's true certainly for EPND in the typical EPD triangle, but I also think it's probably true even for non-product roles, right? I think it's true in marketing, right? Something I'm really pushing for in marketing and I think our marketing team is really leaning into actually is if you can just do all of the thing yourself ... traditionally how a marketing team might operate is like, okay, you have one person who's responsible for executing the performance marketing part of a campaign. They literally go into the Google AdWords interface and they're tweaking the parameters of targeting and budget and conversion tracking, et cetera, and then somebody else is actually responsible for coming up with the specific ad copy, and somebody else yet was responsible for coming up with the seed content or positioning guide written by a PMM that feeds into the ad creative, and so on and so forth, right? Maybe they're promoting some new demo asset that somebody else yet created.

(01:10:35):
I just think that in the same way that you can collapse the roles in EPD, and the ideal person, maybe they're very specialized and deep in one dimension like engineering, but they're well-rounded enough to be dangerous on the other two, I think that's kind of true in almost every other function, right? Sales as well, I think you should start to be able to play more of an SE role. Traditionally salespeople didn't necessarily know the product that well and relied on the SE to come in and be the product experts. I think it's really hard to sell any kind of AI product now without actually being fluent in the product and be able to demo the product, so AEs need to be SE fluent as well.

(01:11:21):
So I just think that that concept of collapsing roles, everybody needs to become more full stack to do the ... being more outcome-oriented, right? Your outcome as an AE is to convince customers of the value of your product and close deals, right? Okay, well, in order to do that, you used to have dependencies on having assets created by marketing and an SE to help you demo. Can you collapse more of those dependencies so that if you had to, you could do it all yourself, right? I just think it's a new operating mentality overall for every AI native company or company that wants to compete in this new arena.

Lenny Rachitsky (01:12:06):
That is a great addition. It almost feels like you go back to startup times when everyone's doing a bunch of stuff. There's no here's the head of product, here's the head of engineering, we're just doing stuff-

Howie Liu (01:12:06):
Totally.

Lenny Rachitsky (01:12:16):
... that needs to be done.

Howie Liu (01:12:17):
Totally.

Lenny Rachitsky (01:12:18):
Yeah, I'm kind of seeing it as this upside down T where there's the thing you're really strong at and then as you described, the minimum of being good at engineering design or ... and SE, by the way, sales engineering imagine is what that stands for. Adjacent roles, you need to start having a baseline. The baseline is increasing of how much you need to understand that, everyone's Venn diagrams are kind of converging.

Howie Liu (01:12:40):
Exactly.

Lenny Rachitsky (01:12:42):
Amazing. Okay, let me take a step back and zoom out and think about the broader journey you've been on over the past decade plus. Let me just ask you this, what's the most counterintuitive lesson you've learned about Airtable building and company building teams that maybe goes against common startup wisdom?

Howie Liu (01:13:02):
I heard your interview with Brian Chesky and then later you talked about founder mode in that YC retreat, and the points there really, really resonated with me. I feel like maybe less eloquently I deduced some of the same principles just in my own experience, which is I think when you're scaling up, and this relates also to what we talked about before around the early days of building a company, you're in the details, you're finding product market fit, you kind of have to be pretty versatile, right? All these decisions from a technical standpoint to design, to even commercial, and what's the freemium model going to be like? And how are we going to market this product? What does the website look like? They're all very intertwined, right? You can't compartmentalize and then almost factory produce each of these things separately. They're all intertwined and you have a very small tight-knit team that's thinking full stack about all of this combined.

(01:14:04):
Obviously that's the only way, in my opinion, to create that magical product market fit in the first place. Then I think as you scale up, the default guidance that you often get from operational experts and larger scale company investors is like, okay, you got to industrialize the process of all of this stuff, right? It's kind of like going from a bespoke artisanal, one person made an entire item of clothing to we got to factory produce this thing, right?

(01:14:38):
What that means in an organizational context is you then create these different fiefdoms, you hire all these execs and each exec just manages their own swim lane, and there's relatively looser coupling between all of those different groups, right? So then you've got sales executing on its own thing, marketing's executing on its own thing, product's executing on its own thing. Even within product there's different product groups and surface areas that are each executing on their own thing.

(01:15:05):
Using the factory metaphor of there's an argument that that's actually kind of an efficient way to scale up production for each of these different swim lanes, right? Each one can operate in a more autonomous and purely scale up focus, wait, how do we produce more of this thing? If the thing happens to be within one product group improving search, that's our main focus. We're just going to go and ship, ship, ship more stuff to improve search. So it's not completely crazy why people give this advice, but I think what you lose is the magical integrative value of holistic thinking and making the bigger picture bets, right?

(01:15:48):
I think Brian talked a lot about this on his episode with you, which is like, look, in a company that is really serious about product, first of all, I really liked his point about the CEO has to play a CPO role, you have to care about the product. Ultimately the product is the thing and you can't just coast on scaling up go-to-market around the product forever, you got to keep innovating on the product. By the way, the best way to innovate on the product is not incrementally split over all these different little surface areas, but actually to have a bigger, more step function vision of how this product needs to make a leap, or what's the next big either act of the product or new capability of the product or reinvention of the product, right?

(01:16:35):
So I think if you really care about doing that from a product execution standpoint and almost refinding new product market fit on a regular basis, I think it necessitates a completely different operating and leadership model throughout the organization. All of the stuff we just talked about in terms of how to operate in the AI native era I think is actually exactly the same as how you need to operate in this constant product market refinding of fit state.

(01:17:02):
So I could not agree more with that concept of you got to think ambitiously and move the organization holistically towards these bigger outcomes, but also ship and learn and experiment a lot more in this era. Then maybe the meta learning I had from all of the above is that the specific advice obviously was like, okay, go scale up in this way or go hire these types of people, experienced operators, et cetera. Now, obviously there's some truth to that, right? The people giving this advice are not incompetent. They had some reason for giving it and in certain contexts that is the right thing to do, but I think my meta learning is it's not enough to just trust the recommendation, like, here's the action you should take from a lot of people, 'cause everybody has different priors and it's almost like we're all our own LLMs, and we all have different training from a different corpus of data informed by our own experiences. Maybe you're trained on the service-

Howie Liu (01:18:00):
... experiences, and maybe you're trained on like the kind of ServiceNow or the Oracle training corpus, and this person's trained on the Facebook corpus, and I'm trained on the Airtable one. I think what I've tried to do more and more is not to just ignore advice from smart people. Obviously, that's not the right answer, but to kind of take their... It's almost like in an LLM you can now with a reasoning model actually inspect the chain of thought and see how it's thinking. Why did it come up with this answer? To me, that chain of thought like "Why did you recommend this?", is actually more informative than the actual, "Just do this recommendation."

(01:18:44):
The answer might be like, "Hey, at So-and-So company, this is how we eliminated the PM role entirely." For Brian at Airbnb, it made sense. We're no longer having PMs in their traditional form. Now, we have program managers and product marketers, but more than the actual decision because I don't think it's a one-size-fits-all, everybody should do the same, why did you do that? The why actually was very informative, and then be able to take that and say like, "Okay, how would I apply that?" Maybe it yields a different outcome, but the reasoning actually is very informative.

Lenny Rachitsky (01:19:19):
It's interesting how this idea founder mode is not so different from this ICCO trend that you're following and it's-

Howie Liu (01:19:26):
For sure.

Lenny Rachitsky (01:19:26):
... yeah, yeah, it's like being in the weeds, being in the details, trying things yourself, not delegating to execs.

Howie Liu (01:19:32):
Yeah, and I think anything taken to an extreme can be problematic. There is a world where you are so in the details and in every detail that you're basically just micromanaging and you're kind of creating like a euphemism for that. That's not really what founder mode is about. That's not like the Brian conception of founder mode is to like micromanage everything and not trust anyone, but I think it's more about finding that right balance of being unabashed about caring about the details that do matter and where the tying together of details across different groups or departments actually is the only way to yield a non-incremental outcome. Otherwise, each person is just optimizing within their own domain, but you'll never get to the global maxima or the global breakthrough. 

(01:20:23):
I think the really cool thing about CEOs as I seize it, frankly any leader playing more of an IC-like role and being in the details is I think for the right type of person, it's actually more fun that way. I mean, to be honest, for me, the times where I felt most disintermediated from what I felt was the substance of this company was when I thought that I was almost like forcing myself to step away from the details. I thought that's what a at-scale CEO was supposed to do. I mean, there's some famous CEOs who have talked about, "The less decision I could make the better. The less details I'm exposed to the better. I just want to inspect at the topmost layer how this business is running, and if everything underneath it is going smoothly, then I'm able to do that and everything looks good."

(01:21:19):
I just think that's maybe, again, it works in a certain type of very mature type of business. Even then, though, I can't imagine that at a CPG company like a Procter & Gamble. You wouldn't want to have a CEO who still actually goes and tastes the soup and tries the products and sees literally the details of what the new product innovation pipeline looks like, as well as like how it's being experienced on the shelves and so on. I don't know. I guess I'm just more and more skeptical that that hands-off pure delegation and process management role ever works as a CEO. Maybe you go through a long enough period of where the business is coasting that nobody notices, but I got to say, for me it's just much more invigorating to get to play that role. I think for the types of operators and leaders that I most admire, that's what makes the job interesting. They don't want to have a automated away kind of role as a leader.

Lenny Rachitsky (01:22:22):
If you could go back in time and whisper something in a decade-ago Howie's ear that would have saved you a lot of pain and suffering over the last decade, what would that be?

Howie Liu (01:22:33):
Don't step away from the details that both you love. I mean, first of all, if your passion is building product and product design, even if it feels like at times the company needs to do all this other stuff like scale up, go to market, and operations and just have like a large people organization, that itself creates a lot of need to do things and manage. There becomes a new job invented just to manage a larger group of people, and obviously you're going to have to do some of that. You can't just completely eschew all your responsibility as an at-scale CEO, but don't lose the essence of the thing that you love doing and that really made this product happen and gives this company as many companies that were founded on a magical product market fit finding insight. Don't step too far away from that, and always make sure that is still your number one, even if other stuff has to also add to your plate.

Lenny Rachitsky (01:23:45):
I think people don't talk enough about this how if someone starts a company that's an idea they have they're excited about, it takes off and then you're stuck on that for a long time, and then even if things are pushed in a direction you're not as excited about. This point about just remembering what you actually love about it and coming back to that is so important because that's the only way to keep doing this for a long time.

Howie Liu (01:24:05):
I think that's so true, and to me that's why there's always been a difference between entrepreneurs who love the act of building a product or the business, too, versus those who saw a just purely business or financial opportunity that they felt like they couldn't pass up exploiting or going after. Look, no knock on people who are more the latter, and there's entire industries where it's all just about alpha generation. You can go into the private equity business and so on, and it's just purely it's rationally about how do I find the alpha? I think that some of the best companies, product central companies, at least in my opinion, are run by those people who actually just love the product. I think you get a feel for that from some of the AI companies like Sam, I think genuinely just loves working on AI.

(01:25:03):
If he could spend a hundred percent of his time on just being close to the AI and the research, I mean, he would and he's even said as much. Ranging to like Brian's with Airbnb, it's pretty clear that people like this are not motivated like... Airbnb was not founded because like, "Oh my God, we want to make a lot of money off this arbitrage opportunity against hotels."

Lenny Rachitsky (01:25:24):
They just needed to pay their rent.

Howie Liu (01:25:26):
Yeah. Well, that and I think they loved the product and I think they also loved the way in which they built the product, the design-centric nature of that product and company and culture. That's what gives you the continued joy of working on what could be the same company for a very long time.

Lenny Rachitsky (01:25:45):
Howie, is there anything else that you wanted to touch on or leave listeners with before we get to our very exciting lightning round?

Howie Liu (01:25:51):
I just want to reiterate, especially for listeners here who are in an EP or D role and especially in the P role, I really do believe that this is not like you either have or you don't like in terms of the skill set needed to be relevant and AI needed, but I do think it's a call to action to go and bolster your skill sets where they may be less refined right now. I think even programming, I really believe everyone could learn how to be a software engineer if they wanted to. Now, obviously, some people just as with like great writers are never going to be a published author or the Hemingway, but everyone can gain a good enough proficiency of software engineering if they really wanted to. 

(01:26:39):
You could take that boot camp. You could do like some coding exercises on the side, et cetera. The point there is that sometimes I think we treat these disciplines like hard, hard skills that if you're already halfway into your career and you're not already an engineer, if you're not already a designer, okay, well, you can never be one. I just think our brains are malleable and there's a lot of great curriculum out there to learn. Lot of it, like I said, just comes down to also like trial and error and building projects, maybe nights and weekends projects even to learn this stuff. Everyone can learn how to be a versatile kind of unicorn product engineer/designer hybrid in the AI-native era. The only thing stopping you is just going out and doing it.

Lenny Rachitsky (01:27:30):
That is a really empowering way to end it, and just to double down on that, it's never been easier to learn these things. There are super intelligences that you can talk to that do a lot as they're building can help you learn.

Howie Liu (01:27:43):
Yeah. I mean, literally, I go into ChatGPT sometimes and I ask it just like, "Hey, how would you build this app?" I'm just curious. I'm like, "How would you build Manus, the open-ended agent?" Literally, how would you build it? You can ask the questions and it's like having an amazing, brilliant software architect, software engineer, product manager, designer expert tutor that you can literally like there's no dumb question. They have infinite patience. They're literally on and awake 24/7. It is the most incredible time to learn this stuff, to your point. Then, of course, the interactive tools to go and actually build stuff. Anyone can download Cursor and just start asking Composer to generate some code for you, and then looking at the code and trying to figure out what it does. To your point, when I think back to the earliest era that I experienced of building apps, first I learned C++, then I learned PHP and JavaScript and even building kind of JavaScript single-page apps in the early days like '08 through 2010. It was a dark, dark art. I mean, there were some like... You just had to go and like learn some of these things. There wasn't great tutorials for it. You had to reverse engineer certain things. There were just weird things like if you wanted rounded corners in your UI, you literally took Photoshop, opened it up, created like a rounded corner in pixels, and then cut that pixel up into an image that you dropped onto the page at exactly the right position to be at the edge of a box.

(01:29:15):
It's like crazy stuff. I mean, everything was so much more arcane at the time, and now it feels so much more fluid and accessible, and the gap between the arcane tech that you have to wade through to build something has just been minimized so much. It's like the effort and abstraction between you and the magical, delightful actual building of the thing that you want has been so minimized. It's never been a more exciting time to be a builder.

Lenny Rachitsky (01:29:47):
You remember spacer.gif?

Howie Liu (01:29:49):
Oh yeah, yeah.

Lenny Rachitsky (01:29:50):
It's like to create. It's that line stuff you just kind of have-

Howie Liu (01:29:52):
Yeah, I remember it. Yeah.

Lenny Rachitsky (01:29:54):
... the invisible one-pixel thing that you just stick in places.

Howie Liu (01:29:57):
Yeah. Yeah, yeah. No.

Lenny Rachitsky (01:29:57):
Oh my God, what a time to be alive. Howie, with that, we've reached our very exciting lightning round. I've got five questions for you. Are you ready?

Howie Liu (01:30:05):
Yes.

Lenny Rachitsky (01:30:05):
Here we go. What are two or three books you find yourself recommending most to other people?

Howie Liu (01:30:09):
You know, I've been trying to read fiction more, partly because I think it's just a really nice mental reset. I will say like Three-Body Problem for anyone who hasn't read it, it's a mind-expanding book. I like sci-fi and fiction that kind of opens your brain, so maybe this is my cheat card, but it's a three-book series. Those are three great books.

Lenny Rachitsky (01:30:30):
I love that series, and my tip there is it gets good one and a half books in is my tip, so just keep reading. That's where it's like, "Okay, now I'm in."

Howie Liu (01:30:40):
I liked even the first one, but I felt like it was inception where every subsequent book was like you dropped into another, like you incepted into another layer, right?

Lenny Rachitsky (01:30:53):
Awesome. Okay. What's a favorite recent movie or TV show you've really enjoyed?

Howie Liu (01:30:57):
TV show, I just started watching The Studio. It's like the Seth Rogen, Rogen.

Lenny Rachitsky (01:31:05):
Yeah, it's so stressful.

Howie Liu (01:31:05):
Yep. Yeah, it is pretty stressful, and I mean, Silicon Valley was too close to home when it came out, so I watched it, but it was just cringy. The Studio is kind of fund to watch because it's a little bit about like inside baseball of Hollywood, and yet I'm not in Hollywood, so it's entertaining to watch. It's I thought smart and a funny show because I split time between L.A. and S.F. I also feel like it's very real to me. I see a lot of the literal characters out there in the world that it's characterizing.

Lenny Rachitsky (01:31:43):
Do you have a favorite product you recently discovered that you really love? Could be an app, could be gadget, could be clothing.

Howie Liu (01:31:48):
Okay, so I'll give two because I feel like I have to say some kind of software product. I mean, I'm a really big fan of Runway, the product and the company. I just think every new model they come out with, they just came out with a new one just I think like two days ago that gives even more controls and refinement on creating exactly the video scene that you want. I think just the photorealism in what you can generate now, and they also built this cool demo thing that's an immersive world generator I mentioned before. I think it's just cool to see. I also like the underdog story. I'm clearly like Google's gunning in the space, has VO3 and so on and has its OpenAI, but I love the underdog story of this sub-hundred-person company still punching above their weight and building really awesome video experiences. That's the software one.

(01:32:45):
Then, a very, very kind of nerdy real-world answer on product is I kind of just recently got into this whole cottage industry of artisanally produced basically clothing by small-scale Japanese manufacturers that use literally like hundred-year-old looms to make clothes the old-fashioned way or the old-fashioned industrial way. They have these loop wheeler machines and they spin the cloth in a very slow pace, so it's completely impractical from a production-scale standpoint, but I've gotten some of these t-shirts and I just love the... I guess in a world where it feels like everything is becoming so much faster moving and even tech from five years ago is obsolete, I love a little bit of the throwback to like old things sometimes can be even more cherishable in this new era. Maybe that makes me a hipster, but I love the vintage, the retro increasingly these days.  

Lenny Rachitsky (01:33:56):
I feel like anything that starts with artisanal small batch Japanese is going to be really good stuff. Is there a brand you want to share that is that? Or is this like you want to keep it-

Howie Liu (01:33:56):
Yeah. No, I mean-

Lenny Rachitsky (01:34:06):
... under the radar.

Howie Liu (01:34:07):
... actually, so Self Edge, which actually has a storefront, the main storefront is on Valencia Street in S.F. They carry a lot of these items. That's kind of their whole MO and they have like jeans and t-shirts. I've gotten a lot. I mean, they basically curate a really good selection of different actual makers. One of them is called Studio D'Artisan, another one's called... Actually, it's cool. There's this company called... I think the umbrella company is actually just Toyo, T-O-Y-O, Manufacturing, which sounds like it's a big kind of like large-scale conglomerate, but it's anything but. It's like a really small-scale Japanese vintage manufacturer of clothing, but they have a few sub-brands.

(01:34:51):
They actually bought the rights to this American post-war brand that was kind of like Hanes, one of the like big four or five menswear, kind of undershirts and athletic wear brands called Whitesville. I don't know where the name came from, but basically it's a bunch of like basic clothing, like t-shirts, et cetera, and this Japanese indie company, they bought the defunct basically name and now is reproducing clothes almost made to the exact shape and stack, and even with the exact recreation of the graphic packaging on these tees, but like today. I just think there's something really funny and ironic about they've taken an American post-war aesthetic and literal brand, but it's actually a indie small-scale Japanese manufacturing approach to making those clothes.

Lenny Rachitsky (01:35:51):
I feel like we just tapped into what could be a whole other podcast conversation about clothing and-

Howie Liu (01:35:56):
Yeah-

Lenny Rachitsky (01:35:56):
... craftsmanship-

Howie Liu (01:35:57):
... [inaudible 01:35:57].

Lenny Rachitsky (01:35:58):
... but I'm going to pull us out of that.

Howie Liu (01:35:59):
The next podcast franchise.

Lenny Rachitsky (01:36:02):
Or just Howie and Lenny talking about clothing.

Howie Liu (01:36:04):
That's great.

Lenny Rachitsky (01:36:05):
Okay, two more questions.

Howie Liu (01:36:06):
Yeah.

Lenny Rachitsky (01:36:06):
Do you have a life motto that you often find useful in working or you like to share with friends or family?

Howie Liu (01:36:12):
I stumbled on this guy Paul Conti, who I think he's an MD, but also a psychologist, and he has a book, but also he did this long-form podcast with Andrew Huberman, and he actually ends up talking a lot about just how to think about your life outlook and kind of your framework for thinking about life, but grounded in a kind of like scientific and neurological and cognitive science basis. I found one particular point really, really powerful it took with me, which is if you live your life in a way that's foundationally built around humility and gratitude. Look, everybody has different circumstances.

(01:37:06):
I think I fully own that even though I didn't come from money, my family was very, very financially modest growing up. I still had incredible resources and opportunities afforded to me even just by virtue of growing up in the U.S., being born in and growing up in the U.S., but also having access to a computer and the internet and even all the free resources I could then access and learn about from there. I still feel like whatever you have or don't have to start with, if you kind of approach the world and kind of the future with a spirit of humility and gratitude rather than, I guess, the opposite of that, I think I've felt like it kind of becomes a self-fulfilling prophecy. You're open-minded, you're kind of grateful, and then more opportunities actually come your way, and maybe it's because the energy you're putting out into the world and other people.

(01:38:07):
You're kind of attracting good opportunities and good people and good things, but I think there's a lot of other parts of his framework, but the one that is easiest to remember is like, how do I approach each day? Even if I'm going through a tough moment and I had to fire somebody today, or maybe I get disappointed because we lost a customer deal or something broke or whatever, but to still try to look at the entire situation from overall a feeling of humility and gratitude I think just really does shift your like... It spills over into everything else for that day and maybe even for the whole lifetime. 

Lenny Rachitsky (01:38:52):
That super resonates. That is really powerful advice that's hard to internalize, but important.

Howie Liu (01:38:57):
Yeah, it's easily said, hard to practice.

Lenny Rachitsky (01:38:59):
Yeah. Where can folks find you? What should they know about Airtable and how can listeners be useful to you?

Howie Liu (01:39:05):
Okay, so I am on Twitter, howietl. I don't post that much, but I'm a lurker, so I listen and watch, and you can always DM me there. You can also email me directly, howie@airtable.com, anytime you have ideas, feedback, et cetera. On Airtable, just go try it. The whole point is we want to make this an experiential product. That's why we're really leaning into the PLG roots. We talked about the homepage literally says like, "Just start building right now. What do you want to build? Go." 

(01:39:36):
It starts building, and so use the product, give me feedback, and if you have ideas of your own and you want to rip on them, I love because my passion is thinking about product and product UX, especially in the AI era if you're working on or thinking about something interesting in that space. Even if it's just purely to riff on a concept, that's something I enjoy doing, and maybe I get to learn and sharpen my own skill set from. Feel free to reach out and, yeah, I mean, tell your friends and family to try Airtable as well. That's the main thing.

Lenny Rachitsky (01:40:08):
Sounds like you're looking for people to nerd snipe you and-

Howie Liu (01:40:10):
Yes. Yeah.

Lenny Rachitsky (01:40:12):
... Howie, thank you so much for being here.

Howie Liu (01:40:14):
Awesome. Thank you, Lenny. 

Lenny Rachitsky (01:40:15):
Bye, everyone. Thank you so much for listening. If you found this valuable, you can subscribe to the show on Apple Podcasts, Spotify, or your favorite podcast app. Also, please consider giving us a rating or leaving a review as that really helps other listeners find the podcast. You can find all past episodes or learn more about the show at lennyspodcast.com. See you in the next episode.

