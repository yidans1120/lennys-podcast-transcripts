---
guest: Aparna Chennapragada
title: 'Microsoft CPO: If you aren’t prototyping with AI you’re doing it wrong | Aparna
  Chennapragada'
youtube_url: https://www.youtube.com/watch?v=HbbfXAWcuUo
video_id: HbbfXAWcuUo
publish_date: 2025-05-18
description: Aparna Chennapragada is the chief product officer of experiences and
  devices at Microsoft, where she oversees AI product strategy for their productivity
  tools and work on agents. Previously,...
duration_seconds: 3673.0
duration: '1:01:13'
view_count: 41098
channel: Lenny's Podcast
keywords:
- pmf
- growth
- retention
- metrics
- okrs
- roadmap
- user research
- iteration
- experimentation
- monetization
- leadership
- management
- strategy
- vision
- market
---

# Microsoft CPO: If you aren’t prototyping with AI you’re doing it wrong | Aparna Chennapragada

## Transcript

Aparna Chennapragada (00:00:00):
I have a cheesy Chrome extension. Literally whenever I open a new tab, it just says, how can you use AI to do what you're going to do right now?

Lenny Rachitsky (00:00:06):
How do you see the future of product development being different?

Aparna Chennapragada (00:00:09):
If you're not prototyping and building to see what you want to build, I think you're doing it wrong. It becomes even more important to have that territorial and taste-making at the heart of it because, otherwise, you just have a Frankenstein product.

Lenny Rachitsky (00:00:23):
There's this acronym that you taught me, NLX. What is that?

Aparna Chennapragada (00:00:26):
Natural language interface. NLX is the new UX. Often I hear a product builders say, "Oh, yeah. With AI, the model eats the products." That doesn't mean it's not designed. You and I are having a conversation. It's a podcast. I'll have another conversation at Microsoft and that's a meeting. Conversations also have grammars. They have structures. They have UI elements. They're invisible. What are the new principles, new constructs in natural language as an interface?

Lenny Rachitsky (00:00:52):
I just saw that Cursor hit 300 million ARR in two years. Interestingly, you guys were very well positioned to do really well in this AI coding tool space. You guys had Copilot, the first tool in the world at this stuff. So ahead of everyone, what happened?

Aparna Chennapragada (00:01:06):
I would say...

Lenny Rachitsky (00:01:08):
Today my guest is Aparna Chennapragada. Aparna is chief product officer at Microsoft where she oversees AI product strategy for their productivity tools and their work on agents. Previously, she was chief product officer at Robinhood, vice president at Google, where she worked on Google lens, search, shopping, augmented reality, AI assistant, and a lot more. She was also a long-time engineering leader at Akamai, and on the board of eBay and Capital One.

(00:01:32):
In our conversation, we chat about how working in B2B is like being Jean-Claude Van Damme doing the splits across two moving trucks, how she's operationalizing her team living in the future so that they're building towards where things are going, why people still need to learn to code, why the PM role isn't going anywhere, why NLX is the new UX, and so much more. If you enjoy this podcast, don't forget to subscribe and follow it in your favorite podcasting app or YouTube. Also, if you become an annual subscriber of my newsletter, you get a year free of a bunch of products including Linear, Superhuman, Notion, Perplexity, and Granola. Check it out at lennysnewsletter.com and click bundle. With that, I bring you Aparna Chennapragada.

(00:02:11):
This episode is brought to you by Eppo. Eppo is a next-generation AB testing and feature management platform built by alums of Airbnb and Snowflake for modern growth teams. Companies like Twitch, Miro, ClickUp, and DraftKings rely on Eppo to power their experiments. Experimentation is increasingly essential for driving growth and for understanding the performance of new features, and Eppo helps you increase experimentation velocity while unlocking rigorous deep analysis in a way that no other commercial tool does.

(00:02:41):
When I was at Airbnb, one of the things that I left most was our experimentation platform, break it, set up experiments, easily troubleshoot issues, and analyze performance all on my own. Eppo does all that and more with advanced statistical methods that can help you shave weeks off experiment time and accessible UI for diving deeper into performance and out-of-the-box reporting that helps you avoid annoying prolonged analytic cycles. Eppo also makes it easy for you to share experiment insights with your team, sparking new ideas for the AB testing flywheel. Eppo powers experimentation across every use case, including product growth, machine learning, monetization, and email marketing. Check out Eppo at geteppo.com/Lenny and 10x your experiment velocity. That's get E-P-P-O .com/Lenny.

(00:03:28):
This episode is brought to you by Pragmatic Institute, the trusted leader in product expertise. Pragmatic Institute helps product professionals turn ideas into impact through proven courses, workshops, and certifications designed for real-world success. For over 30 years, they've trained more than 250,000 product leaders at companies like Google, Microsoft, and Salesforce equipping them with practical strategies to build and scale market-winning products. Pragmatic's full-time instructors each bring over 25 years of hands-on leadership experience, teaching strategies proven to deliver real-world results. And it's not just about what you learn, it's also about who you learn it with. Completing a course connects you to an active community of over 40,000 product professionals. You'll engage in meaningful conversations, collaborate with peers and mentors, and gain direct instructor access to refine your strategies and stay ahead of trends. Get 20% off with code LENNY20 at PragmaticInstitute.com/Lenny. Aparna, thank you so much for being here and welcome to the podcast.

Aparna Chennapragada (00:04:35):
Thank you, Lenny. Thanks for having me.

Lenny Rachitsky (00:04:37):
When I asked a lot of people that work with you, what I should ask you about and what I should know about you, something that came up again and again, it's something that I think most people don't know about you, which is that you're big into stand-up comedy, and you take it semi-seriously. Just how serious are you about this? How much of your life is this and most importantly, how does this help you build better products?

Aparna Chennapragada (00:04:59):
It's hard to say I'm serious about a funny business, but I do watch and do stand-up comedy. I do open mics. I've done a few shows.

Lenny Rachitsky (00:05:09):
Wow.

Aparna Chennapragada (00:05:09):
I have one set brewing that is around AI, unsurprisingly AI and tech and Silicon Valley. It's really interesting for me. This was an accidental discovery. I had always been an SNL fan and Discovery fan, but I went to an open mic because my son sings, and he went to the open mic for singing and he is like, "Mom, you should go do this." And I was like, "Oh, let me go give it a try," and I found that I enjoyed it and was good at it. To your question though, about building better products, I'd say both have PMF, I mean, product market fit, punchline market fit.

(00:05:49):
Actually, there are a couple of things that I do find really powerful and useful because in open mics or even when you're testing these things, it's a very tight cycle of iteration, and you get live... Open mics are the real live experiments. You put something out there, you get very clear micro feedback from users, and then you get tough feedback sometimes. And I think as product builders, that's actually one of the great skills to have, which is you sometimes launch stuff that have a fantastic vision, but the first version is not quite there. And Reid Hoffman says this, "Hey, if you don't launch the first version and are not embedded, you're doing it too slow." Just that gap in closing that, it's good resilience.

Lenny Rachitsky (00:06:30):
Yeah. I never saw these corollaries between these two things. I didn't realize you actually did shows, and you're working on a set. I wasn't going to ask you for a joke, but if you're working on a whole thing about AI, is there something that you can share from that set?

Aparna Chennapragada (00:06:43):
One joke I'd maybe share is people think about these AI chat products as women because you don't know what's going on. It's a black box, and you don't know what they're thinking. There's an entire set around that, but obviously on the flip side too, that they're probably more like men in the sense that they hallucinate a lot. They kind of are not yet reliable.

Lenny Rachitsky (00:07:12):
I'm afraid to laugh with this a little bit. This is great.

Aparna Chennapragada (00:07:16):
And even when they don't know the answer, they make up stuff. They're very confident.

Lenny Rachitsky (00:07:21):
This is good. Where are we going to be seeing the show by the way?

Aparna Chennapragada (00:07:22):
TBD.

Lenny Rachitsky (00:07:24):
Okay. This is great. Okay, let's get serious again. So you worked at most of your career at a lot of consumer internet companies. You worked at Google, Robinhood, you're on the board of eBay, you're on the board of Capital One. Now, you're at Microsoft. I'm curious just what is most different about working at a company like Microsoft and building product at a company like Microsoft?

Aparna Chennapragada (00:07:46):
I think intellectually I knew that, hey, enterprise, particularly the area that I look at most at Microsoft is focused on enterprise and productivity and transforming companies through AI. And to me, I think two things really strike as very different. One, in fact, I just posted about this the other day saying, in consumer, you're kind of like, "Oh, we have a playbook for make the product work or make the feature work and make it delightful," but I think in the enterprise, you almost have... Every time you think you have one use case, you have really two, which is how do you make sure that the feature works well and there's governance of the feature.

(00:08:25):
If you think about even something as simple as sharing a link to a document, you want it to be easy, frictionless, but at the same time, you want that to be secure and safe and being able to have auditability and all of those things. And often, I find that when you go from a consumer enterprise, you fall into a trap of either disregarding that and say, "Oh, we'll just focus on one side of the house," or overly crippling the user experience side and leaning on the other side. So I think there's an art and science and nuance and playbook there too, so that's one big learning for me. The other learning, and especially in the AI era for me has been about this... I think there's a famous trailer from the 2000s on Van Damme on these two buses [inaudible 00:09:13] splits.

Lenny Rachitsky (00:09:14):
Like doing the splits.

Aparna Chennapragada (00:09:14):
Yeah, doing the splits, exactly. I feel like a lot of the companies, including the tech companies, but certainly the enterprises that I talk to are in these two modes where one hand, this is the most compressed tech cycle that we've ever experienced. It's in the order of weeks and months versus years and decades. If you think about mobile and cloud and internet, and there's just so much happening, the intelligence overhang. On the other hand, there's also humans and habits that... Productivity habits change. It's hard to change and change management through the company is also hard. You don't want to be rash on that. So it's like the future is unevenly distributed but even within the companies.

Lenny Rachitsky (00:09:59):
On the second bucket of the bus that Van Damme's riding on of governance and adoption and changing behavior and stuff, is there something you've learned about how to get past that, help that along more?

Aparna Chennapragada (00:10:10):
The thing not to do is hold back folks who are early adopters. I think that's the other one learning. In fact, I think that's one of the reasons why recently... I've been working with folks to say, "Can we have both," which is the longer-term change management, being able to do it in a trusted way, at the same time do this program we are calling Frontier program and roll out cutting edge experimental features. We just built this world's first deep research agent made for work, post-trained for work. And of course, it has all sorts of edges, rough edges, but if there are only adopters in an enterprise or outside, how can we put that in the hands of those folks without insisting that all of the company be completely developing different muscles?

Lenny Rachitsky (00:11:04):
This program Frontier you're talking about, I wanted to spend a little time on it. So what is the idea? The idea here is people are working in this futuristic environment. How does that actually work?

Aparna Chennapragada (00:11:14):
Yeah, I think the idea is exactly this, which is I want to kind of institutionalize and operationalize my personal model of living one year in the future and say, "What does this..." Imagine a company or a setup like Frontier Consulting Group or Frontier Inc., right? And if you did live in that environment where you had all the AI tools and really advanced deep research intelligence on tap, what are the kinds of questions you'd be asking? What's the kind of work you'd be doing? How would you change how you're going about your work day? So that's the premise and you'd say, "Hey, how does it change an individual?" But also down the lane, we want to think about what does a Frontier team look like. We talk a lot about Frontier labs and models. I think models layer is amazing and obviously that's what empowers all these product building to happen, but I want to push us to think about what does a Frontier product look like? And more importantly, how does a Frontier way of working like? What does a team with three people and tons of compute and AI tools look like?

Lenny Rachitsky (00:12:20):
So how exactly does this work? There's a team within Microsoft that's like your job is to use all of our latest tools and build product using that. Does that work?

Aparna Chennapragada (00:12:29):
That is the setup. We are just a few weeks into that setup, but meanwhile what we have done is we've actually set up a fake company and said, "Hey, if you are somebody who wants to come play with some of the cutting edge science projects and deep research agents and agents at work, come party here."

Lenny Rachitsky (00:12:51):
Wow. And it's only a few weeks in. Okay, so TBD how it all goes.

Aparna Chennapragada (00:12:54):
Yeah. And again, these are micro... Let's see. The meta point here also is that in the traditional way, we've kind of always thought about across the companies, across industries, really thinking about roll-outs in these macro ways. You build something and you kind of roll it out, you have a general availability for, and then you take the time. And that's really important too because, again, we are talking about pharma companies, legal companies relying on this. So we do want to have that. But at the same time, given the compressed cycles of AI, how do we start to have people experience what's the one year in the future?

Lenny Rachitsky (00:13:29):
Let's follow this thread in a few different directions. There's how product development changes, there's how engineering changes. There's also just agents. I know you're spending a lot of time in agents, feels like you're not an AI company these days if you're not working on agents or building an agent.

Aparna Chennapragada (00:13:42):
Lenny, you're doing this wrong. You didn't use the word agents so far into the conversation.

Lenny Rachitsky (00:13:51):
I try hard to push it out as far as I can. It's like every conversation in San Francisco, it's just like how long until I start talking about AI? It's like three minutes. Average, I bet. Oh, man. Okay, so with agents, I know that you're leading a lot of this work at Microsoft and a lot of people are wondering what the hell does this mean? What is going to change? Give us just a glimpse into how you see the world being different in a world of agents being around more.

Aparna Chennapragada (00:14:18):
There's a short term and there's a long term, right? There's a lot of hyperventilated, excited talk about the eventual future and all of that. I take a much more practical product building lens on this, and I think about these. At the end of the day, there are tools. Yes, underneath it, there's stochastic models versus very deterministic programming models. You can tell I'm a computer scientist like the way that worldview definitely shapes how I think about this. To me, the short term is there's an evolution. We had apps, and now I think we are firmly in the assistance era where there's human driving the... That's what we think of as co-pilot, right? I think the human driving in the driver's seat but having a lot of assistance from AI.

(00:15:07):
So I think of this as then you look at the dimension of almost autonomy and delegation and intelligence. As the intelligence, for example, when deep reasoning unlock happened, of course, then you can delegate more to the agent. So I think, to me, there's one dimension where you say, "Hey, agents are somewhat independent software processes that can kind of run tasks," and you're not just thinking about handholding and fine motor stuff. You're saying, "Hey, here's my goal. Go make this happen." I'll give you an example. So we are working on this researcher agent for work. And last night, I said, "Hey, I have an important meeting coming up with the leadership team. I really want to present these frameworks here and this is the roadmap here. Go back and look at all the people that are in the meeting. What are their views on this topic and come up with how I should I be thinking about the right persuasion pitch here?"

(00:16:07):
And what's magical about this is not just that it's saving time. Typically, we think about the, so far, AI as summarizing a document or saving time. This is like fighting synapses that I didn't quite have and actually giving me new insights and giving me, dare I say, superpowers. So that's a natural evolution of AI, I would say. So when I think about agents, I think about three things. One is an increasing level of autonomy and kind of independence that you can delegate higher and higher order tasks. Second thing I think of it is complexity. So it's not just a one-shot, "Hey, create this image or do this thing or summarize the document," it's build me this prototype that expresses my idea of, say, an augmented reality app. It's a complex task. And then the third thing I would say is asynchronous. It works when you are not working. I think that's the other big thing about these things that you don't have to sit in front of it.

Lenny Rachitsky (00:17:05):
This answers the question of what is an agent essentially, these three bullet points. So what are the three again?

Aparna Chennapragada (00:17:10):
When I think about agents, I think about these three things. So one, it's autonomy like being... And it's a spectrum, it's not a zero-one, it's how do I actually delegate things that it can do. Second, I think of as complexity. It's not a one-shot, "Hey, summarize this document, generate this image, but it's build me this prototype or help me knock this meeting out of the park." And then the third one I think of is it's a much more natural interaction. That doesn't just mean chat, but it may be actually jumping on a meeting with the agent and being able to talk through all of it or point it to things that I wanted done differently. So I think all three things, the autonomy, the complexity, and the natural interaction are at least product principles that will shape really good ones, good agents.

Lenny Rachitsky (00:17:58):
That is really helpful. Along this line of agents, there's this acronym that you taught me as we were chatting ahead of this podcast, NLX, what is that and how does that relate to agents and why are people not thinking about this enough?

Aparna Chennapragada (00:18:10):
Oh, that's one of my Roman empires these days. The natural language interface. NLX is the new UX. Here's the deal. To me, I think traditionally we've thought very consciously about GUI because the graphical interfaces are not something natural, and so they have had to be explicitly designed, but they're rigid interfaces. What we have with conversational interface and natural language is it's a much more elastic, right? That doesn't mean it's not designed. Often, I hear a product builders say, "Oh, yeah. With AI, the model leads to the product. So it's just you chat with it." You and I are having a conversation, it's a podcast. I'll have another conversation at Microsoft and that's a meeting.

(00:18:59):
So conversations also have grammars, they have structures, they have UI elements, they're invisible. And so one of the things that I see and I'm really excited about is what are the new principles, new constructs in natural language as an interface? I'll give you a few examples. And actually a lot of startups as well as big companies are really experimenting with this stuff. One is if you think about it, prompt itself is a new construct and that's a new UI element just like a dropdown was or a menu was. But others that are emerging, especially for agents, I think are plans. So when you give a high level goal, what we are seeing is that when the agent comes back with a plan, preferably an editable plan, that's a new construct.

(00:19:44):
The other one that I think about a lot is showing the work, progress. You see this with different products. You see with the Copilot, you see with ChatGPT, DeepSeek, this idea of thinking aloud and it's kind of showing the work, but how much do you do it? If it's too verbose, it feels like I'm running some cron job and scripts, but if it's too terse, then I don't know if it's going in the right path, and I don't have the confidence yet. So there are all these new elements. So if you are a product whittler, this is a fun new space to be digging in for product design.

Lenny Rachitsky (00:20:22):
This is really interesting because I think people chat with all these chat bots and it just feels like this is just the way it is, but you actually are designing every element of the interaction, how much to share, but how much you're thinking, here's my plan, what do you think. So I think this will surprise a lot of people, just realizing there's so much that goes into just designing even these what seemingly are simple conversations.

Aparna Chennapragada (00:20:47):
Yeah. Another good example is follow-ups, right? You could say, "Look, you asked me a question," and then I could ask a follow-up set of things, and that's explicitly should be designed for success. So for example, if I said, "Hey, create an image," and it created a black and white like a clip art version of something. What are the next obvious follow-ups that it should be suggesting proactively? Now, too much and you are kind of annoying me, but too little in some sense, you've lost an opportunity to direct me or guide me into a happy path here.

Lenny Rachitsky (00:21:25):
This resonates a lot with when we had Kevin Weil on the podcast, he talked about this question of just how much to show about what you're saying. And it's interesting that DeepSeek went the extreme of just showing everything and people liked it too. I think that was interesting.

Aparna Chennapragada (00:21:39):
Yeah, and I think it's a point in time thing too, Lenny, because in some sense right now these things are such black boxes. They're almost like peeking under the hood for anything. Even if it's verbose feels like, "Oh, I know what's happening," especially because the compute inference time, it's taking long to think. So it just feels like if you just went silent, I'd be very uncomfortable, I think.

Lenny Rachitsky (00:22:02):
I know.

Aparna Chennapragada (00:22:05):
Exactly. So I do feel like there's that point in time, but over time, I also feel like this is an area ripe for personalization. For example, again in human, my API would be very different from somewhere. My interface is probably different from others, and I might just want the direct, "Hey, give me the TLDR," versus the, "Oh, so I went here and then I went there," and I'm like...

Lenny Rachitsky (00:22:28):
Following the start a little bit. We're talking about just how the future is going to be different. There's designing for these chat experiences, there's agents, kind of zooming out to just product development in general, it feels like you're at the forefront of a lot of the tools that are going to change the way we build products and also your teams are working with a lot of these tools that no one else has access to. So let me just ask, how do you see the future of product development being different from today most, and what do you think product builders should be preparing for doing to succeed in that future?

Aparna Chennapragada (00:22:59):
I'll start with one stark statement that I say internally and externally, and I am trying to live it is that in this day and age, if you're not prototyping and building to see what you want to build, I think you're doing it wrong. I call it the prompt sets of the new PRDs. I really insist on folks saying if you're building new projects, new features of course come with prototypes and prompt sets. And I think the notion is not to say, "Hey, now everybody's just a biggest version of a software engineer." It is to say you have the fastest path to seeing and experiencing what's in your mind to be able to communicate, right? It's a much more high bandwidth way of communication. I think about that as a really a loop accelerator in terms of product building. That's number one. When in doubt, as someone put it, demos before memos, right? I think that's really number one.

(00:24:04):
I would say number two, this one is a little bit tricky I'd say, is that what I'm seeing is that the time to first demo is much shorter, but the time to a full deployment is going to take longer. So I think that there's going to be an uneven cadence. So typically, I think there was much more of a you've been this thing, you take a few weeks and then you can iterate and so on. But that inner loop of prototyping and iterating and getting even user research through AI conversations, all of that gets shortened. But I think the bar for scale, therefore becomes much high. In some sense, if you look at it, there's going to be a supply of ideas, a massive increase in supply of ideas in prototypes which is great. It raises the floor, but it raises the ceiling as well. In some sense, how do you break out in these times that you have to make sure that this is something that rises above the noise? So I would say that it's simultaneously thinking about not chasing after every idea. I think is the second one.

(00:25:14):
I'd say the third thing is there's a lot of conversation around full stack builders. What does the team of the future look like? A product building team. What I think about is I think that is inevitable in terms of there will be a few folks that are, especially at the prototyping early idea discovery stage that the lines of blurred, there'll be a few taste makers at the same time. I think you can still have a lot of people experimenting. It becomes even more important to have that editorial and taste making in a Frontier, one or a few at the heart of it because otherwise you just have Frankenstein product. That definitely doesn't change.

(00:25:58):
I have one other additional bonus thing, which is a lot of folks think about, "Oh, don't bother studying computer science or the coding is dead," and I just fundamentally disagree. If anything, I think we've always had higher and higher layers of abstraction in programming. We don't program in assembly anymore. Most of us don't even program in C, and then you're kind of higher and higher layers of abstraction. So to me, they will be ways that you will tell the computer what to do, right? It'll just be at a much higher level of abstraction, which is great. It democratizes. There'll be an order of magnitude more software operators. Instead of Cs, maybe we'll have SOs, but that doesn't mean you don't understand computer science and it's a way of thinking and it's a mental model. So I strongly disagree with the whole coding is dead.

Lenny Rachitsky (00:26:54):
That's awesome. I love that. And SO is a software operator, what is that? What that stands for?

Aparna Chennapragada (00:27:00):
Yeah, I just made it up but yes.

Lenny Rachitsky (00:27:04):
Okay, cool. This idea of prototyping as being kind of core to building these days, is there anything you do within Microsoft to operationalize that and make that just a thing everyone has to do? Is it just culturally do it or is it like you must show me a prototype before you show me it.

Aparna Chennapragada (00:27:20):
Again, the future is here, unevenly distributed, even in Microsoft I would say, but there is certainly a strong cultural momentum and shift and desire to say, "Hey, let's actually look at live demos, live prototypes, and to even communicate the ideas. And to me, I mean, it's not always possible because obviously there are things that are deeply... If you're trying to change something in the bowels of Excel, you probably don't. There's even enough depth in the product that what you need to do, and you don't need to prototype that. But if you're especially thinking about new things and new products, new features, absolutely.

Lenny Rachitsky (00:28:01):
Okay, let's talk about product management. There's this fear that emerged as soon as all these AI coding tools came out of just like PMs are dead, we don't need PMs. We could just build things ourselves. What are these people hanging around for? And what I found is it's actually the opposite that now that coding is easy. Now, the question is more and more, what should we be building? Why should we be building it? Is this right? Is this the right solution? Then getting adoption for it, which is what PMs are really good at. I feel like it's the opposite. PMs are the most important role. It'll change too, but let me get your take. Just what do you think the future of product management looks like? Do you think it's dead? Do you think it's going to thrive? Do you think it's going to change?

Aparna Chennapragada (00:28:41):
Yes. Look, if you are a TPS report, mostly process person, and a lot of companies do get confused about product management and process and project management, I think then you do have a question of, "Hey, what is the value add here," especially if AI can read and write 50,000 meeting notes and track things and send emails and so on, but what I do think on the flip side is the taste making and the editing function becomes really, really important. In a world where the supply of ideas, supply of prototypes becomes even more like an order of magnitude higher, you'd have to think about what is the editing function here.

(00:29:34):
So that does mean that the bar is higher for product folks, but I think there's an interesting side effect I am observing in startups that I'm advising, companies and even within the companies that there used to be more gatekeeping I would say, in terms of like, "Oh, we should ask the product leader what they think." And again, there is a role for that editing function, but you have to earn it now. You just don't get it because of this title, but there's also just unlock of latent really good ideas from smart engineers, smart user researchers, smart designers who now have this expert in their pocket to kind of round out all the other things that they're not typically skilled at to bring forward their ideas and that's amazing, I think.

Lenny Rachitsky (00:30:25):
And I think that expert, it's interesting, I'm working with an engineer on some stuff and he uses ChatGPT to even communicate to me in a more effective ways like, "Turn his pitch into something that will convince Lenny, this is a good idea."

Aparna Chennapragada (00:30:39):
By the way, that is actually one of my common use cases, which is the WWXD I call it. What would X do? I use it to say, "Hey, what would Satya think about this particular set of conversations or ideas that we are pitching and so on." This is the power of, I think deep reasoning plus relevant context, right? This engineer you're talking about has that context about you and so it's kind of very interesting.

Lenny Rachitsky (00:31:06):
If only everyone was as famous as Satya and had so much information out there, but I guess you can import all their emails or whatever tools exist to just understand from the conversations you've had with that person.

Aparna Chennapragada (00:31:17):
Yeah. And I think this goes back to actually what you were saying too, which is I think this idea of what is the... There's like a coil spring. There's an intelligence overhang that I just see across the board. And I think the part of product development has to almost rewire ourselves to, I think, Tobi from Shopify calls it the reflexive AI usage. And that's not as easy, and I've been thinking about why. Basically, I mean, I have a cheesy Chrome extension. Literally whenever I open a new tab, it just says, "How can you use AI to do what you're going to do right now?" It's very cheesy, but it kind of helps to pause and think, "Oh, what am I trying to do here?"

(00:31:56):
But the reason I find it hard, and when I talk even people who are living and breathing in this space, they find it hard is that the updating of the priors is really hard. The models couldn't do some things one year ago. I mean, image generation was full of spellings or reasoning. You just couldn't have deeper and smarter answers. You couldn't do data analysis. So my impression of it from change, trying it a few months ago, that prior needs to be updated. And it's hard to do that, right? You have to do something almost counterintuitive and against the grain to say, "No, no, ignore what you learned about what this can or cannot do." The baby just grew up to be a 15-year-old in a month.

Lenny Rachitsky (00:32:40):
I think that last point is so important that we've tried these tools over the years. And so far, it hasn't been amazing and then all of a sudden it is, and you kind of don't know that and you've given up almost and things change.

Aparna Chennapragada (00:32:53):
I think that's actually... If you are a product builder listening to it, that's a really interesting arbitrage thing for you. If you can kind of cut against the grain and say, "No, I won't have that scar tissue around." This didn't work a few months ago and keep setting high expectations and demand more of the AI today, I think you can unlock more.

Lenny Rachitsky (00:33:15):
There's a lot of alpha in doing that.

Aparna Chennapragada (00:33:18):
That's right.

Lenny Rachitsky (00:33:19):
Today's episode is brought to you by Coda. I personally use Coda every single day to manage my podcast and also to manage my community. It's where I put the questions that I plan to ask every guest that's coming on the podcast, it's where I put my community resources, it's how I manage my workflows. Here's how Coda can help you imagine starting a project at work and your vision is clear, you know exactly who's doing what and where to find the data that you need to do your part. In fact, you don't have to waste time searching for anything because everything your team needs from project trackers and OKRs to documents and spreadsheets lives in one tab all in Coda.

(00:33:54):
With Coda's collaborative all in one workspace, you get the flexibility of docs, the structure of spreadsheets, the power of applications, and the intelligence of AI all in one easy to organize tab. Like I mentioned earlier, I use Coda every single day and more than 50,000 teams trust Coda to keep them more aligned and focused. If you're a startup team looking to increase alignment and agility, Coda can help you move from planning to execution in record time. To try it for yourself, go to coda.io/Lenny today and get six months free of the team plan for startups. That's C-O-D-A .io/Lenny to get started for free and get six months of the team plan, coda.io/Lenny. I'm going to come back to this cheesy plugin, say more about this. So this is a plugin that just lets you put a custom message on every new tab, and you have it say, how can you use AI to do this?

Aparna Chennapragada (00:34:45):
Yeah, it's as cheesy as that. And it's interesting because it works. In the last few weeks alone, I've been doing this experiment to say, "Hey, how much more AI pill can I get?" Both at work and in personal life to say, "When I'm trying to do anything manual, should I be demanding the AI to do this?"

Lenny Rachitsky (00:35:08):
That's so cool. Do you know the name of this Chrome extension by any chance otherwise?

Aparna Chennapragada (00:35:12):
No. No. I built it.

Lenny Rachitsky (00:35:13):
You built a Chrome extension. That's so cool. Okay. Did you use AI to build it?

Aparna Chennapragada (00:35:20):
Of course.

Lenny Rachitsky (00:35:21):
Wow. Which tool did you use to do that? Some kind of Microsoft tool I imagine.

Aparna Chennapragada (00:35:25):
Yes. No, actually, it was just like, I mean, I live in GitHub and GitHub Copilot, so I just was like, "Okay, let's go build this Chrome extension."

Lenny Rachitsky (00:35:33):
Are you releasing this for the general public?

Aparna Chennapragada (00:35:36):
No, I mean, that's the amazing thing. It took me like 10 minutes to do this.

Lenny Rachitsky (00:35:43):
Okay, let's link to it. Let's get it out there, open source this thing. Okay. You mentioned Satya, I have a question about this. So you're one of the very few people that have worked very closely with both Satya and Sundar at Google. Let me ask you this. How do their leadership styles differ, and is there just a fun story you could share about each of them?

Aparna Chennapragada (00:36:02):
Yeah. I do feel lucky to have a window into these two amazing leaders of this generation. I would say, I mean, again, no surprise as you'd expect from CEOs of multi-trillion dollar market cap tech companies, they are 99.99 percentile in almost every dimension you'd think of intellect, empathy, leadership, product, strategy. There are, of course, flavors of differences. I was the technical advisor for Sundar for the first... At Google and set up the office of the CEO there. And they're, again, a matter of time and context because there's a lot more consumer-oriented focus there. So what I did find Sundar great at it is being really calm and measured and thoughtful in terms of making sure that things have... Dealing with the complex ecosystems.

(00:36:57):
If you think about the phone ecosystem or even the search and publisher and advertiser ecosystem, it's a very complex ecosystem. He was a master at that. He's a master at that. And I think on Satya, I find it amazing the appetite he has for learning and fine tuning his mental models and just the zoom levels that he can operate at. The macro, the strategy, what's the game? Also the micro, "Hey, why are we not..." Here's a specific insight that I saw on Twitter, and you can count on the fact that he's ahead of pretty much everybody else in terms of spotting those early things too. So it's just been learning from the firehose as they put it.

Lenny Rachitsky (00:37:39):
What a cool opportunity to work with two incredible folks. Okay, let's go in a whole different direction. Let me just ask you this question that I've been asking people more and more. What's the most counterintuitive lesson that you've learned about building products that goes against common startup wisdom, common product building wisdom.

Aparna Chennapragada (00:37:57):
I don't know if it's as common as it should be, and it's like a counterintuitive thing, but I've repeatedly learned that when you're doing something new, zero-to-one, the temptation is to kind of think about... It's like that South Park episode. Step one, think about the problem. Step two, question-

Lenny Rachitsky (00:37:57):
Underpants. I think it's Underpants, step one.

Aparna Chennapragada (00:38:19):
Underpants. Exactly, right? So I do feel like there's a temptation to rush and say to go to scale before solve. So I've always said to my teams solve before scale. So what that does mean is there's a different posture and different mode when you're trying to solve a problem versus scaling something that's either post-product market fit or even at least in roughly in the ballpark. So to give you a couple of examples, I think when you look at the solved stage, there are wide lurches. You got to be very comfortable with the fact that you're day one thinking about, "Hey, a plant detection tool." And then day 15, you're like, "Oh, actually, the tech is really good for translating foreign language." By the way, this is not hypothetical. This is what we kind of looked at in Google Lens back then and said, "Okay, what is the intersection and so on?"

(00:39:17):
So from the outside, it looks like chaos, but actually, in the... And you should be very comfortable... Not only tolerant, I think you should have an appetite for that because the last thing you want is prematurely fix on one local hill. And then you're climbing that in start-ups and entire product areas and companies, big companies make that mistake and three years later you're like, "Oh, how do I get off this hill?" So I'd say that's one big counterintuitive. When you're trying to think about what mode you're in, are you in the solved mode? Are you in the scale mode? One example is kind of making sure that you're comfortable with the chaos. I think the other lesson I've learned is the danger of metrics. And I think again, if you have worked on Google Search or if you worked on Office products, you really have a very fine-grained sense of what are the metrics for this product?

(00:40:11):
You have the input metrics out, you have the whole shebang, but when you're looking at something zero-to-one. If you decide on a metric two prematurely, that's false precision first of all, right? I mean, CTR. When you have a thousand people, it doesn't mean anything. Retention also may not mean anything. So really being very wary of this big guy, big girl of grownup metrics as I call it, right? You are looking for more qualitative, the sound of click, and what is your... The other kind of the handler uses, what is your set timer and play music? So if you look at Alexa and Siri and Google Assistant and all these things, they had a very promising broad interface. You could say anything, but I think there was one or two things that it was really good at. You could set a timer, you could play music, and you could play trivia. And so you've got to nail those things before you say, "Oh yeah, here you can do anything with it," which is not a good recipe.

Lenny Rachitsky (00:41:11):
Not so funny. That's exactly what I use my Google Home for, so basic. I don't do the trivia thing now maybe I got to give this shot.

Aparna Chennapragada (00:41:20):
Got to try that. Yeah.

Lenny Rachitsky (00:41:21):
There's something along these lines that I've also seen you talk about, which is how to go zero-to-one with something, just a little framework for helping you know if this is the right time for this idea. How do you think about that?

Aparna Chennapragada (00:41:33):
Yeah. And when you think about the solved mode, and this is again sticking with my whole living in one year in the future, I gravitated towards the zero-to-one and solved mode products completely thinking about new category of products. And what I've found, both the hard way I would say, is that you do want to look for at least two out of these three factors, inflection points here if you want to make a really good product. Number one is there a... Shift is a step function in the tech. That's somewhat obvious I would say. Deep learning was one for Google lens. Back then, speech recognition was a step function for conversational search. I would say for Robinhood, the generational shift was very clearly, and the fact that phones were a primary means for you could actually have mobile app for finance that you could use. So look for that inflection. What is the tech inflection? And right now, of course, like LLMs and reasoning models are that step function, but that's not enough.

(00:42:35):
I would say the second factor that we should look for is, what is the consumer behavior shift? So to give you an example, when we started working on Google Lens, what we said is, "Look, people were taking mostly pictures for sharing, selfies and sunsets and so on. And suddenly, when storage became free, mostly free, and everybody had phones everywhere all the time, you took pictures of everything. And then you had enough of pictures or you use the camera as the keyboard for your world, for the real world. And so how do you then say, "Oh, this consumer shift is big, and so therefore, as you go order of magnitude more photos, then you want more to come out of them and you can apply AI to that."

(00:43:24):
And I'd say the third inflection point, particularly I would say in enterprise but also in consumer, is the business model shift. Is there an inflection natural inflection point in the business model? So any great products, if you think about all the way from search, again, the second price option and the fact that you had CPCs, same thing with SaaS and the fact that you could actually charge or monetize enterprise products in a different way. And with AI, of course the monetization is a whole different... We've just barely scratched the surface of whether you do seat monetization, usage like on tap, and then of course outcome-based stuff, outcome-based monetization. Hey, have you solved the problem for me and then I will pay you some fees. So all three to me are kind of like, great, but at least two out of three for a good product.

Lenny Rachitsky (00:44:21):
So this essentially... When investors look at startups, they're always asking, why now? Why is this the time to start this thing? And so your advice here is there's three ways to look at it. Two of these three should be true. There should be a shift in technology, some new technology that has enabled this now recently. There's a shift in consumer behavior, and then there's maybe a new sort of... Or you've invented a new business model, any way to monetize something that it gives you an advantage over folks trying to do it today.

Aparna Chennapragada (00:44:51):
Yep, absolutely.

Lenny Rachitsky (00:44:52):
Awesome. You did mention Robinhood, I think in that example. That was another good example of phones-

Aparna Chennapragada (00:44:56):
Yeah, I mean, talk about the business model of, again, not having a zero fees. And again, that combination of all of these things is what can unlock it. You can't just say, "Oh, we'll just have a much more better intuitive interface and hope that people will switch to it."

Lenny Rachitsky (00:45:16):
Okay, so speaking of zero-to-one products, I'm going to take us to a occasional segment on this podcast that I call Hot Seat Corner. And I have a question for you that is on my mind and it's come up in a couple recent podcasts actually. So there's these companies like Cursor, VZero, Lovable, Bolt, Replit that are the fastest growing company's history. I just saw that Cursor hit 300 million ARR in two years. Interestingly, you guys were very well positioned to do really well in this space, this AI coding tool space. You guys had Copilot, the first tool in the world at this stuff, so ahead of everyone. You build VS Code, which is what all these companies are forking to build on. You have incredible AI infrastructure, incredible AI talent. So this could have been your market. What happened? What happened, Aparna?

Aparna Chennapragada (00:46:01):
It's interesting, the framing... So I'm a dead user of GitHub Copilot, and I would say, "Look, if you unpack..." I think the beauty of this is that code generation has become an amazing tool that LLMs have unlocked. So it is actually really good excitement and action that now code generation has just opened up all of these things that... We talked about the whole idea of prototyping, goes from idea to marks and idea to a clickable prototype in a few minutes. Those are the kinds of things that, of course, we should expect code generation to enable. The way I think about how we are positioned and what we do with GitHub is... So it's a system, not just a product or a set of features.

(00:46:52):
If I think about GitHub, it's for folks who have the repo there and you have... Of course, you have the assistance in terms of autocomplete and you can chat, but now we have the agent board. It's one of the fastest loops that we are seeing, really strong positive feedback. So in some sense, when you have a system, what you are looking for in terms of building and designing it is not just a single product that can grow, but what is the repository? What is your context? What are the set of features that grow from your expertise? If you're a really expert coder, you want the assistance this product needs to scale for that. If you're a wide coder, you should still be able to do that and so on. So that I think is the way that GitHub is positioned to build on and growing honestly really well.

Lenny Rachitsky (00:47:46):
That's so interesting. So the core of this is everyone ends up in GitHub anyway, no matter what tool they use and that's kind of the-

Aparna Chennapragada (00:47:53):
Yeah. The idea again is that code generation as a tool will unlock lot more products. I mean, they're not all competitors to the fact of... They're not all kind of doing the same job. I think when you are... At the end of the day, you are building code for companies to run on, you need to have a system. You need to have kind of the ability, an entire Swiss Army toolkit, not just the autocomplete, not just a chat, not just like a software agent that runs and you kind of hand hold. You need all of this to work together, and that's what the GitHub product is going after.

Lenny Rachitsky (00:48:30):
All roads lead to GitHub. On the flip side of this question, there have been probably 5,000 startups that have tried to disrupt Excel and you guys just keep winning, so something there is working really well.

Aparna Chennapragada (00:48:46):
That is so interesting you say that. So when I came to Microsoft, and I'm an Excel fan, so I actually had a conversation with one of the OG Excel product folks. I was like, "an, what is it about this product?" And he said a couple things that were really interesting for me that just stuck with me. One is and I said, "Hey, Excel is a proof that non-coders also have to program." Programming is really powerful and it's the tool that gives all of the non-coders a really powerful programming ability, and I thought that was just really striking.

(00:49:22):
And then the second thing that I found out super cool, I don't know if you know this, but I didn't know at least before two years ago that there are these amazing Excel championships like World Excel championships where you see folks who can do just magic. And to me, I think the insight here is also that some tools are harder to learn. Perhaps in the beginning there's friction in terms of learning, but great to use. So it's a very good case of, hey, the learning curve initially, the one-time learning curve might be tricky, but it is because there's so much power and depth in the tool.

Lenny Rachitsky (00:50:02):
That's so interesting. I never thought of Excel as a programming language, but it makes sense and I feel like once you get used to it and this is just the way things work, you're kind of stuck there and everything else has to basically copy that model, which is hard to be as good.

Aparna Chennapragada (00:50:13):
Yeah. And I think the depth then the attention that the team has given, and again, that's the compounding effect over decades of working on deep, deep signal from people who depend on it day in and day out.

Lenny Rachitsky (00:50:29):
Okay. To kind of start to close out our conversation, I want to ask this question around your career. I find that most people have one moment in their career that changes the trajectory of their career. It could be a manager they had, it could be a project they worked on, it could be just the job they landed. What would you say is the most pivotal moment in your career that eventually led you to becoming chief product officer at Microsoft?

Aparna Chennapragada (00:50:54):
Actually, there is one moment where it was a turning point for me. I was in Google Search, I was working on this idea that I thought should just work and it didn't. I said, "Hey, these phones are becoming a thing. Personalization has to be important." So I probably banged my head against the wall for a year or so trying to make personalization work. And it turns out when you have a query that you put into Google Search, the personalization didn't matter as much. And so we disbanded the team, but then I think I started working on this product called Google Now, which was a twist on that, which said, "Hey, actually on the phone, we should be able to push content. It's not about searching with personalization." For example, if you have a flight coming up, we should be able to say, "Hey," connect the dots and say, "you should leave now given the traffic and where you need to go," and so on or if you're deeply interested in stand-up comedy with deadpan artists, you should check out Mitch Hedberg.

(00:52:00):
These are kind of these really moments that the smartphone should be smarter. So I let that product through the initial zero-to-one phase, and that was a pivotal moment. It made me realize two things. One, I really love seeing around the corner and kind of seeing where things go and building the product rise to the occasion way more than the scaling and sustaining products. Second, it's harsh, but being early is the same as being wrong. This is pre-LLMs, pre-deep learning a lot of the really amazing ideas in terms of next token predictor, et cetera. We'd been thinking of it but didn't have the horsepower to go... The interface was great, the intelligence wasn't there. And I'd say the third thing that stuck with me is I got to work with some really smart... They talk about talent density now, and I think really smart people who have gone on to do amazing things, and so it gave me a taste of what a small group of people can do.

Lenny Rachitsky (00:53:02):
It's such a great story because it didn't work out in the end. Google Now kind of went away. And by the way, I super remember that product. It was very cool. I remember looking at it was very delightful and happy. And so I also have this segment on the podcast called Failure Corner, where people share a story of failure and how that helped them. And I love this as a combination of those two.

Aparna Chennapragada (00:53:20):
Yeah. I mean, I'm not going to lie. I think it was painful when you do that because you see the vision of what can be and what is, and sometimes it's hard limitations. Sometimes, in this case, it takes five years or 10 years to really unlock the intelligence, but sometimes it's one or two key click stops away from the product being great and part of figuring out is knowing when you're in what situation.

Lenny Rachitsky (00:53:50):
How long was that period from starting out until just moving on and it's not working?

Aparna Chennapragada (00:53:54):
Yeah, I would say in that case, one of the good things is, again, it led the foundation of... It was one of the foundations of the Google Assistant. And of course, as the LLMs step function happened now with Gemini, it kind of works out. And I think it's the same thing across the board, which is sometimes you want to figure out the invariance that do work that then go on to the next version of the product. And other times, you just have to start over.

Lenny Rachitsky (00:54:26):
Is Google Now the first agent before agents? That's what it feels like.

Aparna Chennapragada (00:54:27):
That was certainly the idea, but it is fascinating to me that the interface, that there, we had the opposite problem. Whether you think about all the voice assistants, the interface is like we overshot and the intelligence wasn't there. Today, I feel like there's an opposite problem. I think these things have amazing intelligence and the interface we have largely is like the AOL Dial-Up Modem Chatbot.

Lenny Rachitsky (00:54:55):
We've covered a lot of ground. Is there anything that you wanted to chat about or leave listeners with, maybe a last nugget of wisdom before we get to a very exciting lightning round?

Aparna Chennapragada (00:55:06):
I think I would say one thing that I'm really excited about is this idea of figuring out how we as people and agents collaborate together. I think there's some great set of products and experiences to be reimagined. That's my other Roman empire, which is how do we actually have this co-working space where you have the humans and agents and how do you actually have an output that's much, much more significant than what any one of us or any few of us can produce?

Lenny Rachitsky (00:55:40):
Well, I need to hear more about this. When do you imagine a co-working space of humans and agents? What does this look like? Is this Microsoft teams or is this a physical place with little robots?

Aparna Chennapragada (00:55:51):
Oh, I had a thought of the physical place, but I am thinking a lot about... Right now, all of these experiences are very civil player, and I do think there's an opportunity to think about how do we... Again, I'm living one year in the future, how do we actually have collaborate with each other, but also with agents and really figure out, for example, what tasks can we delegate? What can we inspect? How do we actually have information that flows between people that agents can mediate, and so on.

Lenny Rachitsky (00:56:24):
All right, I'm curious to see what you guys got cooking. With that, we've reached our very exciting lightning round. Are you ready?

Aparna Chennapragada (00:56:32):
Let's do it.

Lenny Rachitsky (00:56:32):
Let's do it. First question, what two or three books that you find yourself recommending most to other people?

Aparna Chennapragada (00:56:38):
Oh, I have recency bias, but I've been reading this book called The Brief History of Intelligence, phenomenal book and like lots of underlining from me. And I think it kind of... The premises too, it looks at the evolution of intelligence like human intelligence and the brain development and connects that to what we are seeing with AI.

Lenny Rachitsky (00:57:02):
Do you have a favorite recent movie or TV show that you've really enjoyed?

Aparna Chennapragada (00:57:05):
Hacks. I've been watching this. It's about a woman who's a great standup comedian of... I think it's set in the fact that she grew up in the '70s and '80s and really tried to break through in an industry that hasn't traditionally been very friendly to women, so really fun and quirky.

Lenny Rachitsky (00:57:31):
Do you have a favorite product that you've recently discovered that you really love, could be an app, could be some physical?

Aparna Chennapragada (00:57:36):
I do use a lot of Microsoft products, GitHub Copilot being one of them, but I think the one that maybe I'll pick is Granola, I think, is the name of the app. I found it really useful. I just gave it a spin the other day and I'm like, "Oh, this is really useful in terms of being able to, again, without being intrusive, just capture the thoughts, notes, and structure it, put some..." It felt like one of those things where, yep, the confidence of a few things like we were talking about like the transcription, real-time transcription tech has gotten really good. Voice recognition is great, and then enough of the LLM magic on top of it to make it structured and contextual.

Lenny Rachitsky (00:58:18):
I am a huge fan of Granola. I'll give a quick picture here. If you become an annual subscriber of my newsletter, you get a year free of Granola for your entire company.

Aparna Chennapragada (00:58:28):
Did not know that.

Lenny Rachitsky (00:58:29):
There we go, and then just check that out, lennysnewsletter.com, and you click the word bundle and you'll see how to do that.

Aparna Chennapragada (00:58:29):
Very cool.

Lenny Rachitsky (00:58:34):
Very cool. Two more questions. Do you have a favorite life motto that you often come back to when you're dealing with something maybe you share with folks that they find useful as well in work or in life?

Aparna Chennapragada (00:58:46):
I have one. In fact, actually, this is my email signature for, I don't know, for the last 20 years or so. It says the best way to predict the future is to invent it. I think it's a quote by Alan Kay. I find it useful for two things. One is no one knows anything. When you think about all the folks who think about, "Hey, this is exactly how everything's going to look and this is exactly the sequence," and so on, I think there's no substitute to experientially building it. I think the second part is if you think there's something that should exist, go build it.

Lenny Rachitsky (00:59:24):
I love that. Final question. We've talked about standup comedy a bit. Is there a favorite under the radar standup comedian that you think people should go check out?

Aparna Chennapragada (00:59:34):
Oh, there's a couple of them. So one, I think, there's an Indian American or I think a British Indian standup comedian. Her name is Sindhu Vee, super smart, mom comedy, and I think the other one that... This is definitely not under the radar, but I just love his stick is Nate Bargatze. He's just so good.

Lenny Rachitsky (00:59:59):
Aparna, this was amazing. Two final questions. Where can folks find you online if they want to reach out maybe and follow up on anything you shared and how can listeners be useful to you?

Aparna Chennapragada (01:00:08):
You can find me on LinkedIn and Twitter. Aparna CD is the handle. I do post stuff a lot more on LinkedIn these days, so would love to hear thoughts, comments, conversations there. I'd say one thing that would be super interesting is if any of this stuff spark conversations, particularly around this, what can a small team with a lot of AI tools do or new products that folks are really excited about, saying that they should exist, hit me up.

Lenny Rachitsky (01:00:42):
Amazing. Aparna, thank you so much for being here.

Aparna Chennapragada (01:00:45):
Thank you.

Lenny Rachitsky (01:00:46):
Bye, everyone. Thank you so much for listening. If you found this valuable, you can subscribe to the show on Apple Podcasts, Spotify, or your favorite podcast app. Also, please consider giving us a rating or leaving a review as that really helps other listeners find the podcast. You can find all past episodes or learn more about the show at lennyspodcast.com. See you in the next episode.

